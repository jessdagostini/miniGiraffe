#+TITLE: IISWC 25 Paper LabBook
#+AUTHOR: Jessica Dagostini
#+STARTUP: overview indent
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* Planning the story of the paper
  - Introduce Giraffe and the pangenome mapping workload
  - Talk about the complexity of this workload and how important it is
  - Workload characterization of Giraffe
  - Discuss complexity, how hard is to make changes to code, etc
  - Present the proxy
  - Validate proxy: needs to run new experiments to validate proxy
    with the version with caching
    Collect hardware metrics and runtime
  - Scalability analysis of the proxy/workload in different CPU
    architectures
    Use Intel (Kaffirlime), AMD (Tangerine), and ARM
    (Chameleon). Might be good to run in another Intel and AMD
    machines (that have different cache capacities)?
  - Discuss different scheduling (omp and workstealing)? Workstealing
    in all machines? Keep discussion of batch sizes?
  - Playing with CachedGBWT
    Explain what it is. Run in different machines with it enabled and
    not. Discuss the potential of autotuning this with different
    sizes. Resizing as needed - doing rehashing to increase
    capacity. Show how this rehash can impact performance on some
    input sets. Try to find a metric or characteristic that make this
    happen (work per thread? hardware characteristcs?)
  - Distributed version with MPI
    Show scalability when running with big number of threads. Link
    this to the caching bottleneck and show how scalability without
    this caching can be good for the application.

  - Contributions
    - Providing a lightweight tool to explore pangenomes
      and sequence-to-graph DNA mapping -- an emerging workflow in HPC
      systems
    - Characterizing the workload of this workflow in different
      architectures using this proxy. Showcase the potential
      benefits of running the full application in different hardware,
      pinpointing what are the characteristics that matter the most for
      performance. This will be one of the few studies in pangenomes that focus on
      computational performance only (other studies on pangenome tools
      focus more on accuracy). Address how the proxy made this study easier.
    - (1) Exploring an existing optimization in the mapping process
      (CachedGBWT) and possible bottlenecks in the current version. OR
      (2) Investigating the scalability in a distributed scenario and
      showcasing possible benefits. Given the complexity of the scheduler in the original
      application, showing how the proxy enabled an easy way to test
      this strategy.
  - Outline per section
    1. Introduction - Brief explanations and motivation with genomics, pangenomes, importance of its
       research. Complexity of scientific applications. Present VG
       Giraffe. Discuss briefly its complexity. Motivate proxies and
       why they are important. Present the work and our contributions.
    2. Background - Further discuss what are pangenomes and the
       process of genome mapping. Explains the variation graph
       strucutre and sequence-to-graph mapping strategy. Present VG
       Giraffe, discussing its procedure and novelty. Discuss the GBWT
       and the other indexing structure VG uses. Explain what are
       proxy applications and their applicability.
    3. Methodology - Describe our proxification strategy,
       coding choices and the analysis workflow. Present the
       characteristics of the machines used in the
       experiemnts. Discuss the input sets, their sizes and their
       representation on the workflow of the application (single and
       pair-ended)
    4. Characterizing Giraffe - Describe Giraffe's execution and
       structure. Present the tracing results and the different steps
       performed by the application to map each read. Discuss the
       parallelization strategy applied and the cost of each
       region. Deep discussion on the most consuming regions and the
       computation they perform. Runtime characteristics. 
    5. Present proxy - Motivate the decision to build the proxy based
       on complexities of the parent application. Describe
       miniGiraffe and what regions it reproduces in the
       code. Describe its input and output, and features that it
       supports (e.g., enable/disable hw counters, tracing). Describe the
       parallelization strategy and the abstractions made on the code. Present
       performance validation data to show how representative miniGiraffe is
       compared to its parent application (hardware metrics like IPC,
       cache hit/miss, # of instructions). Compare scalability
       performance with VG Giraffe. Discuss validation of extension
       results (binary validation of output)
    6. Characterizing pangenome mapping on different hardware -
       Present results of scalability of the different input sets on
       different machines. Showcase the potential benefits of
       different architecture characteristics in this
       workload (with hardware metrics). Pinpoint what matter the most for
       performance, explaining why. Demonstrate how easy it was to test this workload
       in different machines with the proxy.
    (Possible) 7. CachedGBWT - Explain what is this strategy and what it aims to
       bring to the application. Present an analysis of the impact of
       this improvement to the workload on different archs and
       different input sets. Discuss bottlenecks of the current way it
       is structured, linking to a possible metric to identify when
       the bottleneck happens
    (Possible) 7. Distributed version with MPI - Showcase how the
    proxy enabled us to test different approaches by extending this
    application to run in distributed memory. Demonstrate scalability,
    explain why/how the application scales and how the input sets
    determine its scalability (from previous results/conclusions, the
    size of the input set will determine the scalability of the
    application, being bounded by how many reads we are mapping). Use
    this as a use case of the proxy, and motivate how easy it was to
    test this strategy with the proxy instead of the original
    application due to complexities in code and scheduling

    How to justify in the narrative why, of all possible things, we
    decided to choose to go for the CachedGBWT or the MPI path.
* To-do's
  - [X] Find results from the previous submission for Figures 3 and 4
  (Giraffe characterization)
  - [X] Organize ispass-paper folder to backup locally and remove from
  the servers
  - [ ] Design the experiments, creating a python script to run
  everything needed
  - [ ] Crete a new branch on github repo with the submission version of
  the proxy (to make it easy for later)
  - [ ] Upload ~ispass11-all-times.csv.gz~, ~ispass12-all-times.csv.gz~
  ~ispass13-test-all-times.csv.gz~ ~ispass13-Giraffe-all-times.csv.gz~ from HD
* Experiments
- [ ] #1 Validate hw metrics between miniGiraffe vs Giraffe on
  Kaffirlime, sequential execution, 1000GP and yeast
- [ ] #2 Validate runtime between miniGiraffe vs Giraffe on
  Kaffirlime, sequential execution, 1000GP and yeast
- [ ] #3 Validate the output between miniGiraffe vs Giraffe, 1000GP
  and yeast
- [ ] #4 Validate parallel scalability on Kaffirlime, 1000GP and yeast
- [ ] #5 Workload analysis of miniGiraffe over Intel, AMD, and ARM
  architectures
  - [ ] #5.1 Collect scalability on Kaffirlime (Intel)
  - [ ] #5.2 Collect scalability on Tangerine (AMD)
  - [ ] #5.3 Collect scalability on Chameleon (ARM)
  - [ ] #5.4 Collect hw metrics on Tangerine (Sequential, one input
    set)
  - [ ] #5.5 Collect hw metrics on Chameleon (Sequential, one input
    set)
  - [ ] #5.6 Collect hw metrics on Tangerine, parallel, using perf
- [X] #6 Impact of CacheGBWT on the application
  - [X] #6.1 Collect runtime of running miniGiraffe with maximum
    number of threads without the CachedGBWT on Kaffirlime, all test cases
  - [X] #6.2 Collect runtime of running miniGiraffe with maximum
    number of threads without the CachedGBWT and with no-rehash on Tangerine, all test cases
  - [X] #6.3 Collect runtime of running miniGiraffe with maximum
    number of threads without the CachedGBWT on Chameleon, all test cases
  - [X] #6.4 Rehash invesigation for missing test cases (two big ones)
  - [X] #6.5 Validate rehash bottlenech for 1000GP input set
  - [X] #6.6 Understand if the bottleneck for 1000GP is linked to
    number of threads or because of using logical threads
  - [X] #6.7 Find rehash bottleneck for yeast input set
- [ ] #7 - Explore different tuning for each test case
  - [ ] #7.1 Tuning execution on Kaffirlime
  - [ ] #7.2 Tuning execution on Tangerine
  - [ ] #7.3 Tuning execution on another machine
* File location and scripts
- Class/library with general calls (run, copy files, etc) -
  iiswc25/MiniGiraffePipeline.py
* R template for analysis
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 144 × 1
   SOURCE                                                                                                              
   <chr>                                                                                                               
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_0_1000GP_miniGiraffe2048.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_0_1000GP_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_0_1000GP_miniGiraffeNC.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_1_1000GP_miniGiraffe2048.csv
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_1_1000GP_miniGiraffe256.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_1_1000GP_miniGiraffeNC.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_2_1000GP_miniGiraffe2048.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_2_1000GP_miniGiraffe256.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_2_1000GP_miniGiraffeNC.csv  
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_ws_0_1000GP_miniGiraffe2048.csv 
# ℹ 134 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.5
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 4,910 × 8
   Batches Threads Scheduler Repetition CacheSize Query          Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>            <dbl>  <dbl>
 1     512       1 omp                0      2048 reading-gbz      44.8       0
 2     512       1 omp                0      2048 reading-seeds    16.8       0
 3     512       1 omp                0      2048 seeds-loop      191.        0
 4     512       1 omp                0      2048 writing-output    5.27      0
 5     512       1 omp                0       256 reading-gbz      44.7       0
 6     512       1 omp                0       256 reading-seeds    16.9       0
 7     512       1 omp                0       256 seeds-loop      189.        0
 8     512       1 omp                0       256 writing-output    5.28      0
 9     512       1 omp                0         0 reading-gbz      44.7       0
10     512       1 omp                0         0 reading-seeds    16.9       0
# ℹ 4,900 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.6.5 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.5.makespan
#+end_src

Bar plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.5.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

For caching speedup
#+begin_src R :results output :session *R* :exports both
df.6.5.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.5.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 48 × 4
# Groups:   Threads, Scheduler [16]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1       1 omp               0    1   
 2       1 omp             256    1.10
 3       1 omp            2048    1.08
 4       1 ws                0    1   
 5       1 ws              256    1.12
 6       1 ws             2048    1.12
 7       2 omp               0    1   
 8       2 omp             256    1.10
 9       2 omp            2048    1.09
10       2 ws                0    1   
# ℹ 38 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

Line plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.5.2.speedup %>%
  ggplot(aes(x=Threads, y=Speedup, color=Scheduler)) +
  geom_line() +
  geom_point() +
  scale_x_continuous("Threads", breaks=df.5.2.speedup$Threads) +
  facet_wrap(~InputSet) +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 45, hjust = 1, size=15))
#+end_src
* 1 - Validate hw metrics between miniGiraffe and Giraffe on kaffirlime
We will use this data to understand scalability as well
* 5 - Scalability analysis
** Runtime
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             progress=FALSE,
             col_names=TRUE,
             col_types=cols())
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="scalability",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
: # A tibble: 3 × 1
:   SOURCE                                                         
:   <chr>                                                          
: 1 /soe/jessicadagostini/miniGiraffe/iiswc25/scalability-amd.csv  
: 2 /soe/jessicadagostini/miniGiraffe/iiswc25/scalability-arm.csv  
: 3 /soe/jessicadagostini/miniGiraffe/iiswc25/scalability-intel.csv

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "EXP"), sep="/") %>%
    separate(EXP, c("XX6", "Machine"), sep="-") %>%
    mutate(Machine = str_replace_all(Machine, "([.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    print() -> df.5
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 172 × 8
   Machine Threads Scheduler CacheSize InputSet AvgMakespan Baseline Speedup
   <chr>     <dbl> <chr>         <dbl> <chr>          <dbl>    <dbl>   <dbl>
 1 amd           1 omp             256 1000GP         139.      139.    1   
 2 amd           1 omp             256 chm13        20355.    20355.    1   
 3 amd           1 omp             256 grch38        2054.     2054.    1   
 4 amd           1 omp             256 yeast         3290.     3290.    1   
 5 amd           1 ws              256 1000GP         140.      140.    1   
 6 amd           1 ws              256 chm13        20453.    20453.    1   
 7 amd           1 ws              256 grch38        2072.     2072.    1   
 8 amd           1 ws              256 yeast         3223.     3223.    1   
 9 amd           2 omp             256 1000GP          69.9     139.    1.99
10 amd           2 omp             256 chm13        10190.    20355.    2.00
# ℹ 162 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

Bar plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 600 :session *R*
df.5 %>%
  mutate(Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=InputSet)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_grid(Scheduler~Machine, scales="free") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 45, hjust = 1, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figuresV5lpS.png]]

Line plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 600 :session *R*
df.5 %>%
  #filter(Scheduler == "omp") %>%
  ggplot(aes(x=Threads, y=Speedup, color=InputSet)) +
  geom_line() +
  geom_point() +
  scale_x_continuous("Threads", breaks=df.5$Threads) +
  facet_grid(Scheduler~Machine, scales="free_x") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 45, hjust = 1, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figurevmi6wv.png]]

** Hw metrics
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
      rename(Metric = X1, Result = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="hwmetrics",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12 × 1
   SOURCE                                                                                                                   
   <chr>                                                                                                                    
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-4/512_1_omp_0_1000GP_hwmetrics1_miniGiraffe.csv  
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-4/512_1_omp_0_1000GP_hwmetrics2_miniGiraffe.csv  
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-4/512_1_omp_1_1000GP_hwmetrics1_miniGiraffe.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-4/512_1_omp_1_1000GP_hwmetrics2_miniGiraffe.csv  
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-4/512_1_omp_2_1000GP_hwmetrics1_miniGiraffe.csv  
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-4/512_1_omp_2_1000GP_hwmetrics2_miniGiraffe.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/1/512_1_omp_0_1000GP_hwmetrics1_miniGiraffe.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/1/512_1_omp_0_1000GP_hwmetrics2_miniGiraffe.csv
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/1/512_1_omp_1_1000GP_hwmetrics1_miniGiraffe.csv
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/1/512_1_omp_1_1000GP_hwmetrics2_miniGiraffe.csv
11 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/1/512_1_omp_2_1000GP_hwmetrics1_miniGiraffe.csv
12 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/1/512_1_omp_2_1000GP_hwmetrics2_miniGiraffe.csv
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "Machine", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("XX8", "XX9", "XX10", "Repetition", "InputSet", "XX11", "XX12"), sep="_") %>%
    select(-contains("XX")) %>%
    mutate(Machine = case_when(Machine == "amdepyc955464-coreprocessor" ~ "amd",
                               Machine == "intelxeonplatinum8260cpu@240ghz" ~ "intel")) %>% 
    unnest(DATA) %>%
    print() -> df.hw5
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 72 × 6
   Machine Repetition InputSet Metric         Result Thread
   <chr>   <chr>      <chr>    <chr>           <dbl>  <dbl>
 1 amd     0          1000GP   instructions  1.37e12      0
 2 amd     0          1000GP   cycles        5.05e11      0
 3 amd     0          1000GP   L1-access     5.88e11      0
 4 amd     0          1000GP   L1-misses     1.79e 9      0
 5 amd     0          1000GP   LLC-access    5.88e11      0
 6 amd     0          1000GP   LLC-misses    1.79e 9      0
 7 amd     0          1000GP   branch-issued 2.22e11      0
 8 amd     0          1000GP   branch-misses 3.97e 9      0
 9 amd     0          1000GP   DTLB-access   2.19e 8      0
10 amd     0          1000GP   DTLB-misses   3.83e 7      0
# ℹ 62 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.hw5 %>%
  group_by(Machine, InputSet, Metric) %>%
  summarize(Avg = mean(Result),
            Median = median(Result)) %>%
  print() -> df.hw5.summ
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Machine', 'InputSet'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Machine, InputSet [2]
   Machine InputSet Metric                  Avg        Median
   <chr>   <chr>    <chr>                 <dbl>         <dbl>
 1 amd     1000GP   DTLB-access      205425758.    200024367.
 2 amd     1000GP   DTLB-misses       38084535.     37960571.
 3 amd     1000GP   ITLB-access         811999.       817038.
 4 amd     1000GP   ITLB-misses        6590708.      6590472.
 5 amd     1000GP   L1-access     587677517376. 587483372985.
 6 amd     1000GP   L1-misses       1768983342.   1759938080.
 7 amd     1000GP   LLC-access    587682260354. 587661929911.
 8 amd     1000GP   LLC-misses      1768338075.   1759547043.
 9 amd     1000GP   branch-issued 221723711256. 221712129097.
10 amd     1000GP   branch-misses   3982139181.   3976449007.
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.hw5.summ %>%
  select(-Median) %>%
  filter(Metric %in% c("LLC-access", "LLC-misses", "L1-access", "L1-misses")) %>%
  pivot_wider(names_from = Metric, values_from = Avg) %>%
  mutate(RatioLC = 100 * `LLC-misses` / `LLC-access`) %>%
  mutate(RatioL1 = 100 * `L1-misses` / `L1-access`)
#+end_src

#+RESULTS:
: # A tibble: 2 × 8
: # Groups:   Machine, InputSet [2]
:   Machine InputSet   `L1-access` `L1-misses`  `LLC-access` `LLC-misses` RatioLC RatioL1
:   <chr>   <chr>            <dbl>       <dbl>         <dbl>        <dbl>   <dbl>   <dbl>
: 1 amd     1000GP   587677517376. 1768983342. 587682260354.  1768338075.   0.301   0.301
: 2 intel   1000GP   388765411147. 1177250224. 388734700182.  1175801258.   0.302   0.303

#+begin_src R :results output :session *R* :exports both
df.hw5.summ %>%
  select(-Median) %>%
  filter(Metric %in% c("instructions", "cycles")) %>%
  pivot_wider(names_from = Metric, values_from = Avg) %>%
  mutate(IPC = instructions/cycles)
#+end_src

#+RESULTS:
: # A tibble: 2 × 5
: # Groups:   Machine, InputSet [2]
:   Machine InputSet        cycles instructions   IPC
:   <chr>   <chr>            <dbl>        <dbl> <dbl>
: 1 amd     1000GP   505707810086.      1.37e12  2.71
: 2 intel   1000GP   704101787983.      1.38e12  1.95

#+begin_src R :results output :session *R* :exports both
df.hw5.summ %>%
  select(-Median) %>%
  filter(Metric %in% c("DTLB-access", "DTLB-misses", "branch-issued", "branch-misses")) %>%
  pivot_wider(names_from = Metric, values_from = Avg) %>%
  mutate(RatioDTLB = `DTLB-misses` * 100/`DTLB-access`,
         RatioBranch = `branch-misses` * 100/`branch-issued`)
#+end_src

#+RESULTS:
: # A tibble: 2 × 8
: # Groups:   Machine, InputSet [2]
:   Machine InputSet `DTLB-access` `DTLB-misses` `branch-issued` `branch-misses` RatioDTLB RatioBranch
:   <chr>   <chr>            <dbl>         <dbl>           <dbl>           <dbl>     <dbl>       <dbl>
: 1 amd     1000GP      205425758.     38084535.   221723711256.     3982139181.  18.5            1.80
: 2 intel   1000GP   388735976158.     36153698.   222991333209.     4770835122.   0.00930        2.14


* 5.1 - Collect scalability on Intel
** 1000GP
Ran for 6.5 test (can reuse)
** Yeast
Running on June 3
** Grch38
Ran on June 3 (1 exec)
** Chm13
Ran on May 25 (1 exec)
** Analysis
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

Getting some results from another experiment id
#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5"
df.1000GP <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="1000GP(.*)256",
                                 recursive=TRUE,
                                 full.names=TRUE)
             ) %>% print()
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 48 × 1
   SOURCE                                                                                                             
   <chr>                                                                                                              
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_0_1000GP_miniGiraffe256.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_1_1000GP_miniGiraffe256.csv
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_2_1000GP_miniGiraffe256.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_ws_0_1000GP_miniGiraffe256.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_ws_1_1000GP_miniGiraffe256.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_ws_2_1000GP_miniGiraffe256.csv 
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_2_omp_0_1000GP_miniGiraffe256.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_2_omp_1_1000GP_miniGiraffe256.csv
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_2_omp_2_1000GP_miniGiraffe256.csv
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_2_ws_0_1000GP_miniGiraffe256.csv 
# ℹ 38 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

Now get from current experiment id
#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             ) %>%
  bind_rows(df.1000GP) %>%
  print()
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 96 × 1
   SOURCE                                                                                                             
   <chr>                                                                                                              
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_1_omp_0_chm13_miniGiraffe256.csv 
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_1_omp_0_grch38_miniGiraffe256.csv
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_1_omp_0_yeast_miniGiraffe256.csv 
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_1_ws_0_chm13_miniGiraffe256.csv  
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_1_ws_0_grch38_miniGiraffe256.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_1_ws_0_yeast_miniGiraffe256.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_2_omp_0_chm13_miniGiraffe256.csv 
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_2_omp_0_grch38_miniGiraffe256.csv
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_2_omp_0_yeast_miniGiraffe256.csv 
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-1/512_2_ws_0_chm13_miniGiraffe256.csv  
# ℹ 86 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example


#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "InputSet", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.5.1
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 3,260 × 9
   Batches Threads Scheduler Repetition InputSet CacheSize Query           Runtime Thread
     <int>   <int> <chr>          <int> <chr>        <int> <chr>             <dbl>  <dbl>
 1     512       1 omp                0 chm13          256 reading-gbz      31.7        0
 2     512       1 omp                0 chm13          256 reading-seeds  1431.         0
 3     512       1 omp                0 chm13          256 seeds-loop    27045.         0
 4     512       1 omp                0 grch38         256 reading-gbz      21.8        0
 5     512       1 omp                0 grch38         256 reading-seeds   138.         0
 6     512       1 omp                0 grch38         256 seeds-loop     2741.         0
 7     512       1 omp                0 yeast          256 reading-gbz       0.612      0
 8     512       1 omp                0 yeast          256 reading-seeds    54.1        0
 9     512       1 omp                0 yeast          256 seeds-loop     4302.         0
10     512       1 ws                 0 chm13          256 reading-gbz      32.7        0
# ℹ 3,250 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.5.1 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize, InputSet) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize, InputSet) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.5.1.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition', 'CacheSize'. You can override using the `.groups`
argument.
`summarise()` has grouped output by 'Threads', 'Scheduler', 'CacheSize'. You can override using the `.groups` argument.
# A tibble: 64 × 6
# Groups:   Threads, Scheduler, CacheSize [16]
   Threads Scheduler CacheSize InputSet AvgMakespan MedianMakespan
     <int> <chr>         <int> <chr>          <dbl>          <dbl>
 1       1 omp             256 1000GP         186.           185. 
 2       1 omp             256 chm13        27045.         27045. 
 3       1 omp             256 grch38        2741.          2741. 
 4       1 omp             256 yeast         4302.          4302. 
 5       1 ws              256 1000GP         187.           187. 
 6       1 ws              256 chm13        27395.         27395. 
 7       1 ws              256 grch38        2767.          2767. 
 8       1 ws              256 yeast         4322.          4322. 
 9       2 omp             256 1000GP          95.5           95.1
10       2 omp             256 chm13        13687.         13687. 
# ℹ 54 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.5.1.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_grid(InputSet~Scheduler, scales="free") +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureCr1Ifm.png]]

#+begin_src R :results output :session *R* :exports both
df.5.1.makespan %>%
  ungroup() %>%
  arrange(Threads) %>%
  group_by(Scheduler, InputSet) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(-MedianMakespan) %>%
  write_csv("iiswc25/scalability-intel.csv") %>%
  print() -> df.5.1.speedup
#+end_src

#+RESULTS:
#+begin_example
wrote 1.00TB in  0s, 83.89PB/s                                                                                                                          # A tibble: 64 × 7
# Groups:   Scheduler, InputSet [8]
   Threads Scheduler CacheSize InputSet AvgMakespan Baseline Speedup
     <int> <chr>         <int> <chr>          <dbl>    <dbl>   <dbl>
 1       1 omp             256 1000GP         186.      186.    1   
 2       1 omp             256 chm13        27045.    27045.    1   
 3       1 omp             256 grch38        2741.     2741.    1   
 4       1 omp             256 yeast         4302.     4302.    1   
 5       1 ws              256 1000GP         187.      187.    1   
 6       1 ws              256 chm13        27395.    27395.    1   
 7       1 ws              256 grch38        2767.     2767.    1   
 8       1 ws              256 yeast         4322.     4322.    1   
 9       2 omp             256 1000GP          95.5     186.    1.95
10       2 omp             256 chm13        13687.    27045.    1.98
# ℹ 54 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.5.1.speedup %>%
  ggplot(aes(x=Threads, y=Speedup, color=Scheduler)) +
  geom_line() +
  geom_point() +
  scale_x_continuous("Threads", breaks=df.5.2.speedup$Threads) +
  facet_wrap(~InputSet) +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 45, hjust = 1, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figure8F4cTP.png]]

* 5.2 - Collect scalability on AMD
** 1000GP
Ran on May 22
** Yeast
Ran 1 exec on May 26
** Grch38
Ran on May 22
** Chm13
Ran on May 23 (1 exec) - Should set to run one more on the weekend
** Analysis
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 120 × 1
   SOURCE                                                                                                         
   <chr>                                                                                                          
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_omp_0_1000GP_miniGiraffe256.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_omp_0_chm13_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_omp_0_grch38_miniGiraffe256.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_omp_0_yeast_miniGiraffe256.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_omp_1_1000GP_miniGiraffe256.csv
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_omp_2_1000GP_miniGiraffe256.csv
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_ws_0_1000GP_miniGiraffe256.csv 
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_ws_0_chm13_miniGiraffe256.csv  
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_ws_0_grch38_miniGiraffe256.csv 
10 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_ws_0_yeast_miniGiraffe256.csv  
# ℹ 110 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "InputSet", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.5.2
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 5,316 × 9
   Batches Threads Scheduler Repetition InputSet CacheSize Query           Runtime Thread
     <int>   <int> <chr>          <int> <chr>        <int> <chr>             <dbl>  <dbl>
 1     512       1 omp                0 1000GP         256 reading-gbz      31.1        0
 2     512       1 omp                0 1000GP         256 reading-seeds    13.4        0
 3     512       1 omp                0 1000GP         256 seeds-loop      141.         0
 4     512       1 omp                0 chm13          256 reading-gbz      17.3        0
 5     512       1 omp                0 chm13          256 reading-seeds  1080.         0
 6     512       1 omp                0 chm13          256 seeds-loop    20355.         0
 7     512       1 omp                0 grch38         256 reading-gbz      16.0        0
 8     512       1 omp                0 grch38         256 reading-seeds   109.         0
 9     512       1 omp                0 grch38         256 seeds-loop     2054.         0
10     512       1 omp                0 yeast          256 reading-gbz       0.410      0
# ℹ 5,306 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.5.2 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize, InputSet) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize, InputSet) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.5.2.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition', 'CacheSize'. You can override using the `.groups`
argument.
`summarise()` has grouped output by 'Threads', 'Scheduler', 'CacheSize'. You can override using the `.groups` argument.
# A tibble: 80 × 6
# Groups:   Threads, Scheduler, CacheSize [20]
   Threads Scheduler CacheSize InputSet AvgMakespan MedianMakespan
     <int> <chr>         <int> <chr>          <dbl>          <dbl>
 1       1 omp             256 1000GP         139.           140. 
 2       1 omp             256 chm13        20355.         20355. 
 3       1 omp             256 grch38        2054.          2054. 
 4       1 omp             256 yeast         3290.          3290. 
 5       1 ws              256 1000GP         140.           140. 
 6       1 ws              256 chm13        20453.         20453. 
 7       1 ws              256 grch38        2072.          2072. 
 8       1 ws              256 yeast         3223.          3223. 
 9       2 omp             256 1000GP          69.9           69.9
10       2 omp             256 chm13        10190.         10190. 
# ℹ 70 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.5.2.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_grid(InputSet~Scheduler, scales="free") +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-cnMNF9/figurenLpVZo.png]]

#+begin_src R :results output :session *R* :exports both
df.5.2.makespan %>%
  ungroup() %>%
  arrange(Threads) %>%
  group_by(Scheduler, InputSet) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(-MedianMakespan) %>%
  write_csv("iiswc25/scalability-amd.csv") %>%
  print() -> df.5.2.speedup
#+end_src

#+RESULTS:
#+begin_example
wrote 1.00TB in  0s, 20.07PB/s                                                                                                                          # A tibble: 80 × 7
# Groups:   Scheduler, InputSet [8]
   Threads Scheduler CacheSize InputSet AvgMakespan Baseline Speedup
     <int> <chr>         <int> <chr>          <dbl>    <dbl>   <dbl>
 1       1 omp             256 1000GP         139.      139.    1   
 2       1 omp             256 chm13        20355.    20355.    1   
 3       1 omp             256 grch38        2054.     2054.    1   
 4       1 omp             256 yeast         3290.     3290.    1   
 5       1 ws              256 1000GP         140.      140.    1   
 6       1 ws              256 chm13        20453.    20453.    1   
 7       1 ws              256 grch38        2072.     2072.    1   
 8       1 ws              256 yeast         3223.     3223.    1   
 9       2 omp             256 1000GP          69.9     139.    1.99
10       2 omp             256 chm13        10190.    20355.    2.00
# ℹ 70 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.5.2.speedup %>%
  ggplot(aes(x=Threads, y=Speedup, color=Scheduler)) +
  geom_line() +
  geom_point() +
  scale_x_continuous("Threads", breaks=df.5.2.speedup$Threads) +
  facet_wrap(~InputSet) +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 45, hjust = 1, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-cnMNF9/figureJTOkFP.png]]

* 5.3 - Collect scalability on ARM
** 1000GP
Ran on May22 with miniGiraffe 256, NC, and 2048
** Yeast
** Grch38
Ran on May23 miniGiraffe256
** Chm13
** Analysis
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe256",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 84 × 1
   SOURCE                                                                                           
   <chr>                                                                                            
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_omp_0_1000GP_miniGiraffe256.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_omp_0_grch38_miniGiraffe256.csv
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_omp_1_1000GP_miniGiraffe256.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_omp_1_grch38_miniGiraffe256.csv
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_omp_2_1000GP_miniGiraffe256.csv
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_omp_2_grch38_miniGiraffe256.csv
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_ws_0_1000GP_miniGiraffe256.csv 
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_ws_0_grch38_miniGiraffe256.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_ws_1_1000GP_miniGiraffe256.csv 
10 /soe/jessicadagostini/miniGiraffe/iiswc25/thunderx299xx/5-3/512_1_ws_1_grch38_miniGiraffe256.csv 
# ℹ 74 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "InputSet", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.5.3
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,692 × 9
   Batches Threads Scheduler Repetition InputSet CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int> <chr>        <int> <chr>           <dbl>  <dbl>
 1     512       1 omp                0 1000GP         256 reading-gbz     123.       0
 2     512       1 omp                0 1000GP         256 reading-seeds    35.0      0
 3     512       1 omp                0 1000GP         256 seeds-loop      401.       0
 4     512       1 omp                0 grch38         256 reading-gbz      76.5      0
 5     512       1 omp                0 grch38         256 reading-seeds   287.       0
 6     512       1 omp                0 grch38         256 seeds-loop     5689.       0
 7     512       1 omp                1 1000GP         256 reading-gbz     120.       0
 8     512       1 omp                1 1000GP         256 reading-seeds    35.7      0
 9     512       1 omp                1 1000GP         256 seeds-loop      397.       0
10     512       1 omp                1 grch38         256 reading-gbz      78.0      0
# ℹ 1,682 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.5.3 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize, InputSet) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize, InputSet) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.5.3.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition', 'CacheSize'. You can override using the `.groups`
argument.
`summarise()` has grouped output by 'Threads', 'Scheduler', 'CacheSize'. You can override using the `.groups` argument.
# A tibble: 28 × 6
# Groups:   Threads, Scheduler, CacheSize [14]
   Threads Scheduler CacheSize InputSet AvgMakespan MedianMakespan
     <int> <chr>         <int> <chr>          <dbl>          <dbl>
 1       1 omp             256 1000GP          401.           401.
 2       1 omp             256 grch38         5706.          5689.
 3       1 ws              256 1000GP          400.           402.
 4       1 ws              256 grch38         5626.          5631.
 5       2 omp             256 1000GP          211.           211.
 6       2 omp             256 grch38         2864.          2866.
 7       2 ws              256 1000GP          209.           209.
 8       2 ws              256 grch38         2838.          2835.
 9       4 omp             256 1000GP          107.           107.
10       4 omp             256 grch38         1434.          1437.
# ℹ 18 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.5.3.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_grid(InputSet~Scheduler, scales="free") +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figureWZebfj.png]]

#+begin_src R :results output :session *R* :exports both
df.5.3.makespan %>%
  ungroup() %>%
  arrange(Threads) %>%
  group_by(Scheduler, InputSet) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(-MedianMakespan) %>%
  write_csv("iiswc25/scalability-arm.csv") %>%
  print() -> df.5.3.speedup
#+end_src

#+RESULTS:
#+begin_example
wrote 1.00TB in  0s, 49.93PB/s                                                                                                                          # A tibble: 28 × 7
# Groups:   Scheduler, InputSet [4]
   Threads Scheduler CacheSize InputSet AvgMakespan Baseline Speedup
     <int> <chr>         <int> <chr>          <dbl>    <dbl>   <dbl>
 1       1 omp             256 1000GP          401.     401.    1   
 2       1 omp             256 grch38         5706.    5706.    1   
 3       1 ws              256 1000GP          400.     400.    1   
 4       1 ws              256 grch38         5626.    5626.    1   
 5       2 omp             256 1000GP          211.     401.    1.90
 6       2 omp             256 grch38         2864.    5706.    1.99
 7       2 ws              256 1000GP          209.     400.    1.92
 8       2 ws              256 grch38         2838.    5626.    1.98
 9       4 omp             256 1000GP          107.     401.    3.74
10       4 omp             256 grch38         1434.    5706.    3.98
# ℹ 18 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.5.3.speedup %>%
  ggplot(aes(x=Threads, y=Speedup, color=Scheduler)) +
  geom_line() +
  geom_point() +
  scale_x_continuous("Threads", breaks=df.5.2.speedup$Threads) +
  facet_wrap(~InputSet) +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 45, hjust = 1, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figureF7yPIM.png]]

* 5.4 - Getting hardware metrics on AMD
From the scalability results in 5, we have a considerable difference
on performance from the intel and arm machines to the amd one.
* 5.6 - Getting hardware metrics in parallel
I will try to compare the cache references and misses on AMD using
~perf stat~ with the non-cache version and the 256 version, with the
smallest test case

Collected on AMD and Intel
#+begin_src shell :results output :exports both
perf stat -e cache-references,cache-misses ./miniGiraffe2048 dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96 > miniGiraffe2048_cache_parallel_amd.txt 2>&1
perf stat -e cache-references,cache-misses ./miniGiraffe256 dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96 > miniGiraffe256_cache_parallel_amd.txt 2>&1
perf stat -e cache-references,cache-misses ./miniGiraffeNC dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96 > miniGiraffeNC_cache_parallel_amd.txt 2>&1
#+end_src

#+begin_src shell :results output :exports both
tail -n 12 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-6/miniGiraffeNC_cache_parallel_amd.txt
tail -n 12 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-6/miniGiraffe256_cache_parallel_amd.txt
tail -n 12 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-6/miniGiraffe2048_cache_parallel_amd.txt
#+end_src

#+RESULTS:
#+begin_example

 Performance counter stats for './miniGiraffeNC dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96':

    15,721,926,247      cache-references                                                   
       764,787,554      cache-misses                     #    4.864 % of all cache refs    

      53.845671557 seconds time elapsed

     472.341458000 seconds user
      93.699216000 seconds sys



 Performance counter stats for './miniGiraffe256 dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96':

    16,761,796,804      cache-references                                                   
       765,253,777      cache-misses                     #    4.565 % of all cache refs    

      55.747799121 seconds time elapsed

     430.365385000 seconds user
     110.941608000 seconds sys



 Performance counter stats for './miniGiraffe2048 dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96':

    19,578,633,096      cache-references                                                   
       771,269,403      cache-misses                     #    3.939 % of all cache refs    

      55.914327766 seconds time elapsed

     426.776485000 seconds user
     101.489918000 seconds sys


#+end_example

#+begin_src shell :results output :exports both
tail -n 12 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-6/miniGiraffeNC_cache_parallel_intel.txt
tail -n 12 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-6/miniGiraffe256_cache_parallel_intel.txt
tail -n 12 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/5-6/miniGiraffe2048_cache_parallel_intel.txt
#+end_src

#+RESULTS:
#+begin_example

 Performance counter stats for './miniGiraffeNC dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96':

     5,766,195,264      cache-references                                                   
     1,388,556,536      cache-misses                     #   24.081 % of all cache refs    

     100.635771367 seconds time elapsed

    1125.371033000 seconds user
     117.227572000 seconds sys



 Performance counter stats for './miniGiraffe256 dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96':

     6,125,908,380      cache-references                                                   
     1,402,051,645      cache-misses                     #   22.887 % of all cache refs    

      99.691432308 seconds time elapsed

    1004.449677000 seconds user
     121.240763000 seconds sys



 Performance counter stats for './miniGiraffe2048 dump_proxy_novaseq.bin 1000GPlons_hs38d1_filter.giraffe.gbz -t 96':

     6,815,845,803      cache-references                                                   
     1,478,343,942      cache-misses                     #   21.690 % of all cache refs    

      99.639350448 seconds time elapsed

    1023.318066000 seconds user
     120.170780000 seconds sys


#+end_example

| Test Case + Machine        | Cache ref      | Cache miss    | Miss rate % |
| NoCacheGBWT + Intel        | 5,766,195,264  | 1,388,556,536 |     24.081% |
| DefaultCacheGBWT + Intek   | 6,125,908,380  | 1,402,051,645 |     22.887% |
| NoRehashCachedGBWT + Intel | 6,815,845,803  | 1,478,343,942 |     21.690% |
| NoCacheGBWT + AMD          | 15,721,926,247 | 764,787,554   |      4.864% |
| DefaultCacheGBWT + AMD     | 16,761,796,804 | 765,253,777   |      4.565% |
| NoRehashCachedGBW + AMD    | 19,578,633,096 | 771,269,403   |      3.939% |

The percentage of cache misses is way bigger on intel, but the
difference on number of access is huge. why?
It is a significant difference in terms of number of accesses and the
cache miss percentage, and it is the exact same workload.
The caching structure increases the number of cache references in both
machines when comparing with the non-caching version

* 6.1 - Collect runtime of running version without cache and without rehash on Intel
** 1000GP
Almost done. Results are on 6.5
** Yeast
Almost done. Results are on 6.7
** Chm13
** Analysis
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 51 × 1
   SOURCE                                                                                                                
   <chr>                                                                                                                 
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_omp_0_grch38_miniGiraffe2048.csv 
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_omp_0_grch38_miniGiraffe256.csv  
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_omp_0_grch38_miniGiraffe65536.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_omp_0_grch38_miniGiraffeNC.csv   
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_ws_0_grch38_miniGiraffe16384.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_ws_0_grch38_miniGiraffe2048.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_ws_0_grch38_miniGiraffe256.csv   
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_ws_0_grch38_miniGiraffe32768.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_ws_0_grch38_miniGiraffe65536.csv 
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-1/512_24_ws_0_grch38_miniGiraffe8192.csv  
# ℹ 41 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.1
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 3,270 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0      2048 reading-gbz      23.3      0
 2     512      24 omp                0      2048 reading-seeds   138.       0
 3     512      24 omp                0      2048 seeds-loop      132.       0
 4     512      24 omp                0      2048 seeds-loop      131.       1
 5     512      24 omp                0      2048 seeds-loop      131.       2
 6     512      24 omp                0      2048 seeds-loop      130.       3
 7     512      24 omp                0      2048 seeds-loop      131.       4
 8     512      24 omp                0      2048 seeds-loop      130.       5
 9     512      24 omp                0      2048 seeds-loop      130.       6
10     512      24 omp                0      2048 seeds-loop      130.       7
# ℹ 3,260 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.6.1 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.1.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 51 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        166.           166.
 2      24 omp             256        133.           133.
 3      24 omp            2048        132.           132.
 4      24 omp           65536        940.           940.
 5      24 ws                0        165.           165.
 6      24 ws              256        140.           140.
 7      24 ws             2048        134.           134.
 8      24 ws             8192        144.           144.
 9      24 ws            16384        139.           139.
10      24 ws            32768        154.           154.
# ℹ 41 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

Bar plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.1.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-cnMNF9/figurehCIr6Q.png]]

For caching speedup
#+begin_src R :results output :session *R* :exports both
df.6.1.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.1.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 51 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0   1    
 2      24 omp             256   1.25 
 3      24 omp            2048   1.26 
 4      24 omp           65536   0.177
 5      24 ws                0   1    
 6      24 ws              256   1.17 
 7      24 ws             2048   1.23 
 8      24 ws             8192   1.14 
 9      24 ws            16384   1.18 
10      24 ws            32768   1.07 
# ℹ 41 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.1.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-cnMNF9/figurea3n2ym.png]]
Avoid rehash is not good for input sets too big, as is the case
GRCH38.
However, increasing initial capacity and avoiding some rehashing still
brings benefits (see 2048 results).
We could try to find a sweet spot for this.

* 6.4 - Investigate rehash on missing tests
** GRCH38
Ran corrected version May 26.
Tried to run with 131072 but it never ended executing, so I am
guessing it is not possible to run... Since there were just two
occurrences that needed that much of thread, I will try the half one,
65536.
**Update** - Running with this new size was 10x more slow. Let's try to
  find a sweeter spot. I will try to reduce to half agai. Let's go
  with 32768
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 61 × 1
   SOURCE                                                                                                                
   <chr>                                                                                                                 
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_omp_0_grch38_miniGiraffe16384.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_omp_0_grch38_miniGiraffe2048.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_omp_0_grch38_miniGiraffe256.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_omp_0_grch38_miniGiraffe4096.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_omp_0_grch38_miniGiraffe65536.csv
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_omp_0_grch38_miniGiraffe8192.csv 
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_omp_0_grch38_miniGiraffeNC.csv   
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_ws_0_grch38_miniGiraffe16384.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_ws_0_grch38_miniGiraffe2048.csv  
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-4/512_24_ws_0_grch38_miniGiraffe256.csv   
# ℹ 51 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.4
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 3,818 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0     16384 reading-gbz      22.0      0
 2     512      24 omp                0     16384 reading-seeds   140.       0
 3     512      24 omp                0     16384 seeds-loop      142.       0
 4     512      24 omp                0     16384 seeds-loop      141.       1
 5     512      24 omp                0     16384 seeds-loop      141.       2
 6     512      24 omp                0     16384 seeds-loop      141.       3
 7     512      24 omp                0     16384 seeds-loop      142.       4
 8     512      24 omp                0     16384 seeds-loop      142.       5
 9     512      24 omp                0     16384 seeds-loop      141.       6
10     512      24 omp                0     16384 seeds-loop      142.       7
# ℹ 3,808 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.6.4 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.4.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 61 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        166.           166.
 2      24 omp             256        133.           133.
 3      24 omp            2048        132.           132.
 4      24 omp            4096        138.           138.
 5      24 omp            8192        136.           136.
 6      24 omp           16384        143.           143.
 7      24 omp           65536        940.           940.
 8      24 ws                0        165.           165.
 9      24 ws              256        140.           140.
10      24 ws             2048        134.           134.
# ℹ 51 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

Bar plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.4.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figuremyueyO.png]]

For caching speedup
#+begin_src R :results output :session *R* :exports both
df.6.4.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.4.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 61 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0   1    
 2      24 omp             256   1.25 
 3      24 omp            2048   1.26 
 4      24 omp            4096   1.20 
 5      24 omp            8192   1.22 
 6      24 omp           16384   1.16 
 7      24 omp           65536   0.177
 8      24 ws                0   1    
 9      24 ws              256   1.17 
10      24 ws             2048   1.23 
# ℹ 51 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.4.speedup %>%
  filter(Threads == 96)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 4
# Groups:   Threads, Scheduler [2]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      96 omp               0  1     
 2      96 omp             256  1.40  
 3      96 omp            2048  1.44  
 4      96 omp            4096  1.36  
 5      96 omp            8192  1.36  
 6      96 omp           16384  1.21  
 7      96 omp           32768  0.705 
 8      96 omp           65536  0.0626
 9      96 ws                0  1     
10      96 ws              256  1.21  
11      96 ws             2048  1.24  
12      96 ws             4096  1.25  
13      96 ws             8192  1.25  
14      96 ws            16384  1.08  
15      96 ws            32768  0.730 
16      96 ws            65536  0.0550
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
my_custom_colors <- c("#D95F02", "#7570B3", "#E7298A", 
                      "#66A61E", "#E6AB02", "#A6761D", "#666666")
df.6.4.speedup %>%
  filter(CacheSize > 0 & Scheduler == "omp") %>%
  mutate(CacheSize = factor(CacheSize, levels = c(0, 256, 2048, 4096, 8192, 16384, 32768, 65536), ordered=TRUE),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  geom_hline(yintercept = 1, linetype = "dashed") +
  scale_fill_manual(values = my_custom_colors) +
  facet_wrap(~Scheduler) +
  theme_bw()+
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 0, hjust = 0.5, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figurenrAHA2.png]]
Avoid rehash is not good for input sets too big, as is the case
GRCH38.
However, increasing initial capacity and avoiding some rehashing still
brings benefits (see 2048 results).
We could try to find a sweet spot for this.
UPDATE: in fact, avoid rehash completely for this test case reduces
speed significantly. My guess goes to the hashing structure used to
store this cached GBWT structure.
However, for most of the tests, the best speedup was not with the
default size of 256, but with increased size of 2048 (on OMP this can
be seen with 24, 48, and 96 threads, WS this happens with 24, 48, and
72 threads)

* 6.2 - Collect runtime of running version without cached and wihtout rehash on AMD
I will run with 32, 64, 96, 128 threads for each input set
** 1000GP
Running 2048 and NC on May 27. 256 already ran on 5.2
** Yeast
** Grch38
Need to re-run, need to find out the maximum cache resize (have run
with 2048, which is the max size for other test case)
** Chm13
** Analysis
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 1
   SOURCE                                                                                                          
   <chr>                                                                                                           
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_128_omp_0_grch38_miniGiraffeNC.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_128_omp_1_grch38_miniGiraffeNC.csv
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_128_omp_2_grch38_miniGiraffeNC.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_128_ws_0_grch38_miniGiraffeNC.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_128_ws_1_grch38_miniGiraffeNC.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_128_ws_2_grch38_miniGiraffeNC.csv 
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_32_omp_0_grch38_miniGiraffeNC.csv 
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_32_omp_1_grch38_miniGiraffeNC.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_32_omp_2_grch38_miniGiraffeNC.csv 
10 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-2/512_32_ws_0_grch38_miniGiraffeNC.csv  
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.2
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,968 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512     128 omp                0         0 reading-gbz      13.9      0
 2     512     128 omp                0         0 reading-seeds   106.       0
 3     512     128 omp                0         0 seeds-loop       27.4      0
 4     512     128 omp                0         0 seeds-loop       27.5      1
 5     512     128 omp                0         0 seeds-loop       28.6      2
 6     512     128 omp                0         0 seeds-loop       27.4      3
 7     512     128 omp                0         0 seeds-loop       26.9      4
 8     512     128 omp                0         0 seeds-loop       27.5      5
 9     512     128 omp                0         0 seeds-loop       27.4      6
10     512     128 omp                0         0 seeds-loop       26.0      7
# ℹ 1,958 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="grch38",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 20 × 1
   SOURCE                                                                                                           
   <chr>                                                                                                            
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_omp_0_grch38_miniGiraffe256.csv  
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_1_ws_0_grch38_miniGiraffe256.csv   
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_128_omp_0_grch38_miniGiraffe256.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_128_ws_0_grch38_miniGiraffe256.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_16_omp_0_grch38_miniGiraffe256.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_16_ws_0_grch38_miniGiraffe256.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_2_omp_0_grch38_miniGiraffe256.csv  
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_2_ws_0_grch38_miniGiraffe256.csv   
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_32_omp_0_grch38_miniGiraffe256.csv 
10 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_32_ws_0_grch38_miniGiraffe256.csv  
11 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_4_omp_0_grch38_miniGiraffe256.csv  
12 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_4_ws_0_grch38_miniGiraffe256.csv   
13 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_64_omp_0_grch38_miniGiraffe256.csv 
14 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_64_ws_0_grch38_miniGiraffe256.csv  
15 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_72_omp_0_grch38_miniGiraffe256.csv 
16 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_72_ws_0_grch38_miniGiraffe256.csv  
17 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_8_omp_0_grch38_miniGiraffe256.csv  
18 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_8_ws_0_grch38_miniGiraffe256.csv   
19 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_96_omp_0_grch38_miniGiraffe256.csv 
20 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/5-2/512_96_ws_0_grch38_miniGiraffe256.csv
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  filter(Threads %in% c(128, 96, 64, 32)) %>%
  print() -> df.5.2
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 656 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512     128 omp                0       256 reading-gbz      15.9      0
 2     512     128 omp                0       256 reading-seeds   109.       0
 3     512     128 omp                0       256 seeds-loop       21.7      0
 4     512     128 omp                0       256 seeds-loop       22.0      1
 5     512     128 omp                0       256 seeds-loop       21.8      2
 6     512     128 omp                0       256 seeds-loop       21.7      3
 7     512     128 omp                0       256 seeds-loop       21.5      4
 8     512     128 omp                0       256 seeds-loop       21.6      5
 9     512     128 omp                0       256 seeds-loop       21.2      6
10     512     128 omp                0       256 seeds-loop       21.3      7
# ℹ 646 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.2 %>%
  bind_rows(df.5.2) %>%
  print() -> df.6.2
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 2,624 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512     128 omp                0         0 reading-gbz      13.9      0
 2     512     128 omp                0         0 reading-seeds   106.       0
 3     512     128 omp                0         0 seeds-loop       27.4      0
 4     512     128 omp                0         0 seeds-loop       27.5      1
 5     512     128 omp                0         0 seeds-loop       28.6      2
 6     512     128 omp                0         0 seeds-loop       27.4      3
 7     512     128 omp                0         0 seeds-loop       26.9      4
 8     512     128 omp                0         0 seeds-loop       27.5      5
 9     512     128 omp                0         0 seeds-loop       27.4      6
10     512     128 omp                0         0 seeds-loop       26.0      7
# ℹ 2,614 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.6.2 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.2.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 16 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      32 omp               0        80.3           80.2
 2      32 omp             256        66.8           66.8
 3      32 ws                0        82.8           82.8
 4      32 ws              256        67.9           67.9
 5      64 omp               0        43.5           43.0
 6      64 omp             256        34.8           34.8
 7      64 ws                0        47.7           47.9
 8      64 ws              256        37.5           37.5
 9      96 omp               0        36.9           37.0
10      96 omp             256        28.4           28.4
11      96 ws                0        40.0           40.0
12      96 ws              256        30.9           30.9
13     128 omp               0        29.4           29.3
14     128 omp             256        23.3           23.3
15     128 ws                0        34.9           35.1
16     128 ws              256        25.3           25.3
#+end_example

Bar plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.2.makespan %>%
  filter(Scheduler == "omp") %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figurexTBKp0.png]]

For caching speedup
#+begin_src R :results output :session *R* :exports both
df.6.2.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.2.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      32 omp               0    1   
 2      32 omp             256    1.20
 3      32 ws                0    1   
 4      32 ws              256    1.22
 5      64 omp               0    1   
 6      64 omp             256    1.25
 7      64 ws                0    1   
 8      64 ws              256    1.27
 9      96 omp               0    1   
10      96 omp             256    1.30
11      96 ws                0    1   
12      96 ws              256    1.29
13     128 omp               0    1   
14     128 omp             256    1.27
15     128 ws                0    1   
16     128 ws              256    1.38
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.2.speedup %>%
  filter(Scheduler == "omp" & CacheSize > 0) %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  ylim(0.0, 1.5) +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 0, hjust = 0.5, size=15)) 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureqJAfcQ.png]]
#+begin_src R :results output :session *R* :exports both
df.6.2.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.2.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 8 × 4
# Groups:   Threads, Scheduler [8]
  Threads Scheduler CacheSize Speedup
    <int> <chr>         <int>   <dbl>
1      32 omp             256       1
2      32 ws              256       1
3      64 omp             256       1
4      64 ws              256       1
5      96 omp             256       1
6      96 ws              256       1
7     128 omp             256       1
8     128 ws              256       1
#+end_example

* 6.5 - Validate rehash bottleneck 1000GP
Pipeline file - pipeline-6-5.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 144 × 1
   SOURCE                                                                                                              
   <chr>                                                                                                               
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_0_1000GP_miniGiraffe2048.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_0_1000GP_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_0_1000GP_miniGiraffeNC.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_1_1000GP_miniGiraffe2048.csv
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_1_1000GP_miniGiraffe256.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_1_1000GP_miniGiraffeNC.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_2_1000GP_miniGiraffe2048.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_2_1000GP_miniGiraffe256.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_omp_2_1000GP_miniGiraffeNC.csv  
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-5/512_1_ws_0_1000GP_miniGiraffe2048.csv 
# ℹ 134 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.5
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 4,910 × 8
   Batches Threads Scheduler Repetition CacheSize Query          Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>            <dbl>  <dbl>
 1     512       1 omp                0      2048 reading-gbz      44.8       0
 2     512       1 omp                0      2048 reading-seeds    16.8       0
 3     512       1 omp                0      2048 seeds-loop      191.        0
 4     512       1 omp                0      2048 writing-output    5.27      0
 5     512       1 omp                0       256 reading-gbz      44.7       0
 6     512       1 omp                0       256 reading-seeds    16.9       0
 7     512       1 omp                0       256 seeds-loop      189.        0
 8     512       1 omp                0       256 writing-output    5.28      0
 9     512       1 omp                0         0 reading-gbz      44.7       0
10     512       1 omp                0         0 reading-seeds    16.9       0
# ℹ 4,900 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.5 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.5.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 48 × 5
# Groups:   Threads, Scheduler [16]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1       1 omp               0       205.           205. 
 2       1 omp             256       186.           185. 
 3       1 omp            2048       189.           190. 
 4       1 ws                0       210.           209. 
 5       1 ws              256       187.           187. 
 6       1 ws             2048       187.           187. 
 7       2 omp               0       105.           106. 
 8       2 omp             256        95.5           95.1
 9       2 omp            2048        96.9           97.2
10       2 ws                0       108.           107. 
# ℹ 38 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.5.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figureOWPgpY.png]]

#+begin_src R :results output :session *R* :exports both
df.6.5.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  write_csv("iiswc25/xeonplatinum8260.csv") %>%
  print() -> df.6.5.speedup
#+end_src

#+RESULTS:
#+begin_example
wrote 1.00TB in  0s, 62.60PB/s                                                                                                                          # A tibble: 48 × 4
# Groups:   Threads, Scheduler [16]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1       1 omp               0    1   
 2       1 omp             256    1.10
 3       1 omp            2048    1.08
 4       1 ws                0    1   
 5       1 ws              256    1.12
 6       1 ws             2048    1.12
 7       2 omp               0    1   
 8       2 omp             256    1.10
 9       2 omp            2048    1.09
10       2 ws                0    1   
# ℹ 38 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.5.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figurelP17u9.png]]
There is a metric that makes the rehash to be a bottleneck from 48
threads. It get even slower than no using cache at all.
I want to check if the slowdown of the cached version is because we
are using logic threads or it is linked to the number of threads.

One more thing to observe.
#+begin_src R :results output :session *R* :exports both
df.6.5.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.5.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 32 × 4
# Groups:   Threads, Scheduler [16]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1       1 omp             256   1    
 2       1 omp            2048   0.982
 3       1 ws              256   1    
 4       1 ws             2048   1.00 
 5       2 omp             256   1    
 6       2 omp            2048   0.986
 7       2 ws              256   1    
 8       2 ws             2048   0.998
 9       4 omp             256   1    
10       4 omp            2048   0.953
# ℹ 22 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.5.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figurejc1zxQ.png]]
Comparing speedup between rehash or not, not doing rehash almost get
2x speedup for this test with 96 threads in this machine.

* 6.6 - Understand bottleneck - Logical threads vs Number of threads
To validate this, I will reserve a node in Chameleon that has at least
72 physical threads, and validate the behavior.

Differences between this intel machine and kaffirlime     
|               | Kaffirlime - Platinum 8260 | Chameleon - Platinum 8380 | Chameleon - Gold6240R | Chameleon - Gold6126 |
| Frequency     | 2.40GHz                    | 2.30GHz                   | 2.40GHz               | 2.60GHz              |
| L1 Cache      | 1.5MB                      | 3.8MB                     | 1.5MB                 | 768KiB               |
| L3 Cache      | 71.5MB                     | 120MB                     | 71.5MB                | 38.5MiB              |
| # of cores    | 24 * 2                     | 40 * 2                    | 24 * 2                | 12 * 2               |
| Total threads | 96                         |                           | 96                    | 48                   |

Cache is way bigger on this machine.

lscpu of the machine I used for the first test
#+begin_src shell :results output :exports both
Architecture:             x86_64
  CPU op-mode(s):         32-bit, 64-bit
  Address sizes:          46 bits physical, 57 bits virtual
  Byte Order:             Little Endian
CPU(s):                   160
  On-line CPU(s) list:    0-159
Vendor ID:                GenuineIntel
  Model name:             Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz
    CPU family:           6
    Model:                106
    Thread(s) per core:   2
    Core(s) per socket:   40
    Socket(s):            2
    Stepping:             6
    CPU(s) scaling MHz:   26%
    CPU max MHz:          3400.0000
    CPU min MHz:          800.0000
    BogoMIPS:             4600.00
    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpui
                          d aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat
                          _l3 intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt av
                          x512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect wbnoinvd dtherm ida arat pln pts vnmi avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq
                           avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid fsrm md_clear pconfig flush_l1d arch_capabilities
Virtualization features:  
  Virtualization:         VT-x
Caches (sum of all):      
  L1d:                    3.8 MiB (80 instances)
  L1i:                    2.5 MiB (80 instances)
  L2:                     100 MiB (80 instances)
  L3:                     120 MiB (2 instances)
NUMA:                     
  NUMA node(s):           2
  NUMA node0 CPU(s):      0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94,96,98,100,102,104,106,108,110,112,114,116,118,120,122,124,126,128,130,132,134,136,138,140
                          ,142,144,146,148,150,152,154,156,158
  NUMA node1 CPU(s):      1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141
                          ,143,145,147,149,151,153,155,157,159
Vulnerabilities:          
  Gather data sampling:   Mitigation; Microcode
  Itlb multihit:          Not affected
  L1tf:                   Not affected
  Mds:                    Not affected
  Meltdown:               Not affected
  Mmio stale data:        Mitigation; Clear CPU buffers; SMT vulnerable
  Reg file data sampling: Not affected
  Retbleed:               Not affected
  Spec rstack overflow:   Not affected
  Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl
  Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization
  Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditional; RSB filling; PBRSB-eIBRS SW sequence; BHI SW loop, KVM SW loop
  Srbds:                  Not affected
  Tsx async abort:        Not affected
#+end_src

Pipeline file - pipeline-6-6.py
** Analysis
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 1
   SOURCE                                                                                                               
   <chr>                                                                                                                
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_24_omp_0_1000GP_miniGiraffe2048.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_24_omp_0_1000GP_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_24_omp_0_1000GP_miniGiraffeNC.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_24_ws_0_1000GP_miniGiraffe2048.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_24_ws_0_1000GP_miniGiraffe256.csv  
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_24_ws_0_1000GP_miniGiraffeNC.csv   
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_48_omp_0_1000GP_miniGiraffe2048.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_48_omp_0_1000GP_miniGiraffe256.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_48_omp_0_1000GP_miniGiraffeNC.csv  
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8380cpu@230ghz/6-6/512_48_ws_0_1000GP_miniGiraffe2048.csv 
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.6
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,512 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0      2048 reading-gbz     52.2       0
 2     512      24 omp                0      2048 reading-seeds   18.8       0
 3     512      24 omp                0      2048 seeds-loop       9.28      0
 4     512      24 omp                0      2048 seeds-loop       9.54      1
 5     512      24 omp                0      2048 seeds-loop       9.59      2
 6     512      24 omp                0      2048 seeds-loop       9.48      3
 7     512      24 omp                0      2048 seeds-loop       9.52      4
 8     512      24 omp                0      2048 seeds-loop       9.55      5
 9     512      24 omp                0      2048 seeds-loop       9.50      6
10     512      24 omp                0      2048 seeds-loop       9.50      7
# ℹ 1,502 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.6 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.6.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0       10.6           10.6 
 2      24 omp             256        9.49           9.49
 3      24 omp            2048        9.59           9.59
 4      24 ws                0       10.4           10.4 
 5      24 ws              256        9.54           9.54
 6      24 ws             2048        9.52           9.52
 7      48 omp               0        5.71           5.71
 8      48 omp             256        6.03           6.03
 9      48 omp            2048        5.19           5.19
10      48 ws                0        6.24           6.24
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.6.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figureHUYbKK.png]]

#+begin_src R :results output :session *R* :exports both
df.6.6.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  write_csv("iiswc25/xeonplatinum8380.csv") %>%
  print() -> df.6.6.speedup
#+end_src

#+RESULTS:
#+begin_example
wrote 1.00TB in  0s, 45.59PB/s                                                                                                                          # A tibble: 24 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0   1    
 2      24 omp             256   1.12 
 3      24 omp            2048   1.11 
 4      24 ws                0   1    
 5      24 ws              256   1.09 
 6      24 ws             2048   1.10 
 7      48 omp               0   1    
 8      48 omp             256   0.947
 9      48 omp            2048   1.10 
10      48 ws                0   1    
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.6.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figureSRbyFZ.png]]
This is a good result! This means that the speedup of avoiding rehash
with a bigger number of threads for 1000GP input set is due to some
metric linked to number of reads being processed, or something like
that, and not because of using virtual threads. CachedGBWT is in fact
a bottleneck for performance in some settings, mainly when the test
case is not that big.

I need to validate this behavior with a bigger test (i.e. yeast or
something). I should repeat this test with yeast, but trying to
reduce its size until I can see this bottleneck happening there.
** Another machine with less cache
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 72 × 1
   SOURCE                                                                                                           
   <chr>                                                                                                            
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_0_1000GP_miniGiraffe2048.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_0_1000GP_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_0_1000GP_miniGiraffeNC.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_1_1000GP_miniGiraffe2048.csv
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_1_1000GP_miniGiraffe256.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_1_1000GP_miniGiraffeNC.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_2_1000GP_miniGiraffe2048.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_2_1000GP_miniGiraffe256.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_omp_2_1000GP_miniGiraffeNC.csv  
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6126cpu@260ghz/6-6/512_24_ws_0_1000GP_miniGiraffe2048.csv 
# ℹ 62 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.6
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 4,488 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0      2048 reading-gbz      62.9      0
 2     512      24 omp                0      2048 reading-seeds    20.1      0
 3     512      24 omp                0      2048 seeds-loop       11.8      0
 4     512      24 omp                0      2048 seeds-loop       12.1      1
 5     512      24 omp                0      2048 seeds-loop       11.9      2
 6     512      24 omp                0      2048 seeds-loop       11.8      3
 7     512      24 omp                0      2048 seeds-loop       12.1      4
 8     512      24 omp                0      2048 seeds-loop       12.2      5
 9     512      24 omp                0      2048 seeds-loop       12.0      6
10     512      24 omp                0      2048 seeds-loop       11.8      7
# ℹ 4,478 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.6.6 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.6.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        14.6           14.4
 2      24 omp             256        13.0           12.8
 3      24 omp            2048        12.2           12.2
 4      24 ws                0        15.2           15.2
 5      24 ws              256        13.9           13.9
 6      24 ws             2048        13.9           14.1
 7      48 omp               0        14.2           13.9
 8      48 omp             256        11.6           11.2
 9      48 omp            2048        10.3           10.3
10      48 ws                0        13.6           13.6
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

Bar plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.6.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-xe2tVe/figurekoCudp.png]]

For caching speedup
#+begin_src R :results output :session *R* :exports both
df.6.6.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  write_csv("iiswc25/xeongold6126.csv") %>%
  print() -> df.6.6.speedup
#+end_src

#+RESULTS:
#+begin_example
wrote 1.00TB in  0s, 45.59PB/s                                                                                                                          # A tibble: 24 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.12
 3      24 omp            2048    1.19
 4      24 ws                0    1   
 5      24 ws              256    1.09
 6      24 ws             2048    1.09
 7      48 omp               0    1   
 8      48 omp             256    1.22
 9      48 omp            2048    1.38
10      48 ws                0    1   
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.6.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-xe2tVe/figurel2L9O9.png]]
Despite the good results, this machine just have 24 physical threads
and 48 logical threads. This means that the reuslts with 72 and 96
threads are not exactly valids, since I am using way more threads than
available.
Still, we got better results with the avoiding rehash version with 24
and 48 threads, so this might be promising.
** Another machine different CPU same cache
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 40 × 1
   SOURCE                                                                                                            
   <chr>                                                                                                             
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_omp_0_1000GP_miniGiraffe2048.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_omp_0_1000GP_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_omp_0_1000GP_miniGiraffeNC.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_omp_1_1000GP_miniGiraffeNC.csv  
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_omp_2_1000GP_miniGiraffeNC.csv  
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_ws_0_1000GP_miniGiraffe2048.csv 
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_ws_0_1000GP_miniGiraffe256.csv  
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_ws_0_1000GP_miniGiraffeNC.csv   
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_ws_1_1000GP_miniGiraffeNC.csv   
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeongold6240rcpu@240ghz/6-6/512_24_ws_2_1000GP_miniGiraffeNC.csv   
# ℹ 30 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.6
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 2,520 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0      2048 reading-gbz      62.3      0
 2     512      24 omp                0      2048 reading-seeds    22.5      0
 3     512      24 omp                0      2048 seeds-loop       12.2      0
 4     512      24 omp                0      2048 seeds-loop       12.1      1
 5     512      24 omp                0      2048 seeds-loop       12.1      2
 6     512      24 omp                0      2048 seeds-loop       12.1      3
 7     512      24 omp                0      2048 seeds-loop       12.2      4
 8     512      24 omp                0      2048 seeds-loop       12.1      5
 9     512      24 omp                0      2048 seeds-loop       12.1      6
10     512      24 omp                0      2048 seeds-loop       12.1      7
# ℹ 2,510 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

For grouping makespan
#+begin_src R :results output :session *R* :exports both
df.6.6 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.6.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0       13.0           12.9 
 2      24 omp             256       11.9           11.9 
 3      24 omp            2048       12.2           12.2 
 4      24 ws                0       12.6           12.6 
 5      24 ws              256       11.5           11.5 
 6      24 ws             2048       11.4           11.4 
 7      48 omp               0        8.19           8.23
 8      48 omp             256        7.29           7.29
 9      48 omp            2048        7.06           7.06
10      48 ws                0        9.43           9.47
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

Bar plot
#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.6.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figure3VYpJG.png]]

For caching speedup
#+begin_src R :results output :session *R* :exports both
df.6.6.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  write_csv("iiswc25/xeongold6240r.csv") %>%
  print() -> df.6.6.speedup
#+end_src

#+RESULTS:
#+begin_example
wrote 1.00TB in  0s, 62.60PB/s                                                                                                                          # A tibble: 24 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.09
 3      24 omp            2048    1.06
 4      24 ws                0    1   
 5      24 ws              256    1.10
 6      24 ws             2048    1.11
 7      48 omp               0    1   
 8      48 omp             256    1.12
 9      48 omp            2048    1.16
10      48 ws                0    1   
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.6.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-3a1M9r/figureYJiU2g.png]]
What is going on with 96 threads?? How to explain this?
** Everything together
Group reading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             progress=FALSE,
             col_names=TRUE,
             col_types=cols())
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="xeon",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
: # A tibble: 4 × 1
:   SOURCE                                                        
:   <chr>                                                         
: 1 /soe/jessicadagostini/miniGiraffe/iiswc25/xeongold6126.csv    
: 2 /soe/jessicadagostini/miniGiraffe/iiswc25/xeongold6240r.csv   
: 3 /soe/jessicadagostini/miniGiraffe/iiswc25/xeonplatinum8260.csv
: 4 /soe/jessicadagostini/miniGiraffe/iiswc25/xeonplatinum8380.csv

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "Machine"), sep="/") %>%
    mutate(Machine = str_replace_all(Machine, "([.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
  print() -> df.6.6
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 120 × 5
   Machine      Threads Scheduler CacheSize Speedup
   <chr>          <dbl> <chr>         <dbl>   <dbl>
 1 xeongold6126      24 omp               0    1   
 2 xeongold6126      24 omp             256    1.12
 3 xeongold6126      24 omp            2048    1.19
 4 xeongold6126      24 ws                0    1   
 5 xeongold6126      24 ws              256    1.09
 6 xeongold6126      24 ws             2048    1.09
 7 xeongold6126      48 omp               0    1   
 8 xeongold6126      48 omp             256    1.22
 9 xeongold6126      48 omp            2048    1.38
10 xeongold6126      48 ws                0    1   
# ℹ 110 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.6 %>%
  group_by(Machine, CacheSize) %>%
  summarize(max(Speedup))
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Machine'. You can override using the `.groups` argument.
# A tibble: 12 × 3
# Groups:   Machine [4]
   Machine          CacheSize `max(Speedup)`
   <chr>                <dbl>          <dbl>
 1 xeongold6126             0           1   
 2 xeongold6126           256           1.22
 3 xeongold6126          2048           1.38
 4 xeongold6240r            0           1   
 5 xeongold6240r          256           2.44
 6 xeongold6240r         2048           2.25
 7 xeonplatinum8260         0           1   
 8 xeonplatinum8260       256           1.15
 9 xeonplatinum8260      2048           1.51
10 xeonplatinum8380         0           1   
11 xeonplatinum8380       256           1.16
12 xeonplatinum8380      2048           1.15
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.6 %>%
  filter(Scheduler == "omp" & Threads > 24 & CacheSize > 0 & Machine %in% c("xeonplatinum8260", "xeonplatinum8380")) %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  geom_hline(yintercept = 1, linetype = "dashed") +
  facet_grid(Scheduler~Machine) +
  theme_bw()+
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 45, hjust = 1, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureZ3acr3.png]]
What is going on with 96 threads?? How to explain this?
* 6.7 - Find yeast bottleneck
I need to first downsize yeast by more than I was doing.
According to previous investigation, I have 33713104 sequences to map
in yeast. I have tried cutting by half and 1/4 and still did not see
any bottleneck happening with rehashing and cachegbwt.
** First trial - 1/6
I will try to cut even more this time, by 6
#+begin_src R :results output :session *R* :exports both
33713104 / 6
#+end_src

#+RESULTS:
: [1] 5618851

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast_miniGiraffe",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 1
   SOURCE                                                                                                              
   <chr>                                                                                                               
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast_miniGiraffe2048.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast_miniGiraffeNC.csv  
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast_miniGiraffe2048.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast_miniGiraffe256.csv  
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast_miniGiraffeNC.csv   
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast_miniGiraffe2048.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast_miniGiraffe256.csv 
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast_miniGiraffeNC.csv  
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_ws_0_yeast_miniGiraffe2048.csv 
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,488 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0      2048 reading-gbz     0.617      0
 2     512      24 omp                0      2048 reading-seeds   9.07       0
 3     512      24 omp                0      2048 seeds-loop     37.1        0
 4     512      24 omp                0      2048 seeds-loop     37.2        1
 5     512      24 omp                0      2048 seeds-loop     37.0        2
 6     512      24 omp                0      2048 seeds-loop     37.1        3
 7     512      24 omp                0      2048 seeds-loop     37.1        4
 8     512      24 omp                0      2048 seeds-loop     37.1        5
 9     512      24 omp                0      2048 seeds-loop     37.1        6
10     512      24 omp                0      2048 seeds-loop     37.2        7
# ℹ 1,478 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        46.0           46.0
 2      24 omp             256        34.2           34.2
 3      24 omp            2048        37.2           37.2
 4      24 ws                0        48.1           48.1
 5      24 ws              256        35.1           35.1
 6      24 ws             2048        35.5           35.5
 7      48 omp               0        29.4           29.4
 8      48 omp             256        21.3           21.3
 9      48 omp            2048        22.9           22.9
10      48 ws                0        29.5           29.5
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureJPeHvx.png]]

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.34
 3      24 omp            2048    1.24
 4      24 ws                0    1   
 5      24 ws              256    1.37
 6      24 ws             2048    1.36
 7      48 omp               0    1   
 8      48 omp             256    1.38
 9      48 omp            2048    1.29
10      48 ws                0    1   
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureBRRPNO.png]]
No-rehash seems to be good when running on workstealing, but by too
slightly thing. Let's try to get it more small.
** Second trial - 1/7
#+begin_src R :results output :session *R* :exports both
33713104 / 7
#+end_src

#+RESULTS:
: [1] 4816158

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast-seve",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 1
   SOURCE                                                                                                                   
   <chr>                                                                                                                    
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-seven_miniGiraffe2048.c…
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-seven_miniGiraffe256.csv
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-seven_miniGiraffeNC.csv 
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-seven_miniGiraffe2048.csv
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-seven_miniGiraffe256.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-seven_miniGiraffeNC.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-seven_miniGiraffe2048.c…
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-seven_miniGiraffe256.csv
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-seven_miniGiraffeNC.csv 
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_ws_0_yeast-seven_miniGiraffe2048.csv
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,488 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0      2048 reading-gbz     0.620      0
 2     512      24 omp                0      2048 reading-seeds   7.64       0
 3     512      24 omp                0      2048 seeds-loop     28.1        0
 4     512      24 omp                0      2048 seeds-loop     28.1        1
 5     512      24 omp                0      2048 seeds-loop     28.1        2
 6     512      24 omp                0      2048 seeds-loop     28.1        3
 7     512      24 omp                0      2048 seeds-loop     28.1        4
 8     512      24 omp                0      2048 seeds-loop     28.1        5
 9     512      24 omp                0      2048 seeds-loop     28.1        6
10     512      24 omp                0      2048 seeds-loop     28.1        7
# ℹ 1,478 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        36.9           36.9
 2      24 omp             256        29.0           29.0
 3      24 omp            2048        28.1           28.1
 4      24 ws                0        34.7           34.7
 5      24 ws              256        28.4           28.4
 6      24 ws             2048        28.3           28.3
 7      48 omp               0        23.6           23.6
 8      48 omp             256        18.6           18.6
 9      48 omp            2048        20.5           20.5
10      48 ws                0        25.9           25.9
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-xe2tVe/figureZ1WHvM.png]]

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.27
 3      24 omp            2048    1.31
 4      24 ws                0    1   
 5      24 ws              256    1.22
 6      24 ws             2048    1.23
 7      48 omp               0    1   
 8      48 omp             256    1.27
 9      48 omp            2048    1.15
10      48 ws                0    1   
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-xe2tVe/figureb4Gguj.png]]
No-rehash seems to be good when running on workstealing, but by too
slightly thing. Let's try to get it more small.
** Third trial - 1/8
#+begin_src R :results output :session *R* :exports both
33713104 / 8
#+end_src

#+RESULTS:
: [1] 4214138

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast-eight",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 32 × 1
   SOURCE                                                                                                                   
   <chr>                                                                                                                    
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-eight_miniGiraffe16384.…
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-eight_miniGiraffe2048.c…
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-eight_miniGiraffe256.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-eight_miniGiraffeNC.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-eight_miniGiraffe16384.c…
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-eight_miniGiraffe2048.csv
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-eight_miniGiraffe256.csv 
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-eight_miniGiraffeNC.csv  
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-eight_miniGiraffe16384.…
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-eight_miniGiraffe2048.c…
# ℹ 22 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,984 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0     16384 reading-gbz     0.621      0
 2     512      24 omp                0     16384 reading-seeds   6.72       0
 3     512      24 omp                0     16384 seeds-loop     24.8        0
 4     512      24 omp                0     16384 seeds-loop     24.8        1
 5     512      24 omp                0     16384 seeds-loop     24.7        2
 6     512      24 omp                0     16384 seeds-loop     24.7        3
 7     512      24 omp                0     16384 seeds-loop     24.8        4
 8     512      24 omp                0     16384 seeds-loop     24.8        5
 9     512      24 omp                0     16384 seeds-loop     24.8        6
10     512      24 omp                0     16384 seeds-loop     24.8        7
# ℹ 1,974 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop" & CacheSize != 2048) %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        30.6           30.6
 2      24 omp             256        26.0           26.0
 3      24 omp           16384        24.9           24.9
 4      24 ws                0        33.0           33.0
 5      24 ws              256        28.8           28.8
 6      24 ws            16384        24.8           24.8
 7      48 omp               0        23.4           23.4
 8      48 omp             256        18.5           18.5
 9      48 omp           16384        18.2           18.2
10      48 ws                0        24.1           24.1
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figuret78H55.png]]

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  mutate(Machine = "Intel") %>%
  mutate(Inputset = "1/8") %>%
  print() -> df.intel.1.8
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 7
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>   
 1      24 omp               0        30.6           30.6 Intel   1/8     
 2      24 omp             256        26.0           26.0 Intel   1/8     
 3      24 omp           16384        24.9           24.9 Intel   1/8     
 4      24 ws                0        33.0           33.0 Intel   1/8     
 5      24 ws              256        28.8           28.8 Intel   1/8     
 6      24 ws            16384        24.8           24.8 Intel   1/8     
 7      48 omp               0        23.4           23.4 Intel   1/8     
 8      48 omp             256        18.5           18.5 Intel   1/8     
 9      48 omp           16384        18.2           18.2 Intel   1/8     
10      48 ws                0        24.1           24.1 Intel   1/8     
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.18
 3      24 omp           16384    1.23
 4      24 ws                0    1   
 5      24 ws              256    1.15
 6      24 ws            16384    1.33
 7      48 omp               0    1   
 8      48 omp             256    1.26
 9      48 omp           16384    1.28
10      48 ws                0    1   
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureb28jc9.png]]
Getting this size was more effective on no-rehashing.

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp             256   1    
 2      24 omp           16384   1.04 
 3      24 ws              256   1    
 4      24 ws            16384   1.16 
 5      48 omp             256   1    
 6      48 omp           16384   1.01 
 7      48 ws              256   1    
 8      48 ws            16384   0.970
 9      72 omp             256   1    
10      72 omp           16384   1.02 
11      72 ws              256   1    
12      72 ws            16384   0.993
13      96 omp             256   1    
14      96 omp           16384   1.00 
15      96 ws              256   1    
16      96 ws            16384   1.04
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureA9FGqX.png]]
Speedup of not doing rehash is not that significant on yeast, even
with a really smaller number of sequences to map. Still, we do have
some scenarios where not doing rehash is better than doing.
** Fourth trial - 1/10
#+begin_src R :results output :session *R* :exports both
33713104 / 10
#+end_src

#+RESULTS:
: [1] 3371310

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast-ten",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 1
   SOURCE                                                                                                                   
   <chr>                                                                                                                    
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-ten_miniGiraffe16384.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-ten_miniGiraffe256.csv  
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-ten_miniGiraffeNC.csv   
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-ten_miniGiraffe16384.csv 
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-ten_miniGiraffe256.csv   
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_yeast-ten_miniGiraffeNC.csv    
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-ten_miniGiraffe16384.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-ten_miniGiraffe256.csv  
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-ten_miniGiraffeNC.csv   
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_ws_0_yeast-ten_miniGiraffe16384.csv 
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,488 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0     16384 reading-gbz     0.616      0
 2     512      24 omp                0     16384 reading-seeds   5.41       0
 3     512      24 omp                0     16384 seeds-loop     20.1        0
 4     512      24 omp                0     16384 seeds-loop     20.0        1
 5     512      24 omp                0     16384 seeds-loop     19.9        2
 6     512      24 omp                0     16384 seeds-loop     20.0        3
 7     512      24 omp                0     16384 seeds-loop     20.0        4
 8     512      24 omp                0     16384 seeds-loop     20.0        5
 9     512      24 omp                0     16384 seeds-loop     20.0        6
10     512      24 omp                0     16384 seeds-loop     20.0        7
# ℹ 1,478 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 24 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        25.9           25.9
 2      24 omp             256        20.3           20.3
 3      24 omp           16384        20.1           20.1
 4      24 ws                0        24.8           24.8
 5      24 ws              256        20.2           20.2
 6      24 ws            16384        20.8           20.8
 7      48 omp               0        17.3           17.3
 8      48 omp             256        13.8           13.8
 9      48 omp           16384        15.2           15.2
10      48 ws                0        19.1           19.1
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figure9Tbcwa.png]]

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  mutate(Machine = "Intel") %>%
  mutate(Inputset = "1/10") %>%
  print() -> df.intel.1.10
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 7
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>   
 1      24 omp               0        25.9           25.9 Intel   1/10    
 2      24 omp             256        20.3           20.3 Intel   1/10    
 3      24 omp           16384        20.1           20.1 Intel   1/10    
 4      24 ws                0        24.8           24.8 Intel   1/10    
 5      24 ws              256        20.2           20.2 Intel   1/10    
 6      24 ws            16384        20.8           20.8 Intel   1/10    
 7      48 omp               0        17.3           17.3 Intel   1/10    
 8      48 omp             256        13.8           13.8 Intel   1/10    
 9      48 omp           16384        15.2           15.2 Intel   1/10    
10      48 ws                0        19.1           19.1 Intel   1/10    
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.27
 3      24 omp           16384    1.29
 4      24 ws                0    1   
 5      24 ws              256    1.23
 6      24 ws            16384    1.19
 7      48 omp               0    1   
 8      48 omp             256    1.25
 9      48 omp           16384    1.14
10      48 ws                0    1   
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureQh2wJl.png]]
Getting this size was more effective on no-rehashing.

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp             256   1    
 2      24 omp           16384   1.01 
 3      24 ws              256   1    
 4      24 ws            16384   0.970
 5      48 omp             256   1    
 6      48 omp           16384   0.910
 7      48 ws              256   1    
 8      48 ws            16384   1.12 
 9      72 omp             256   1    
10      72 omp           16384   0.976
11      72 ws              256   1    
12      72 ws            16384   1.00 
13      96 omp             256   1    
14      96 omp           16384   1.11 
15      96 ws              256   1    
16      96 ws            16384   0.987
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figurePMT8CG.png]]
Speedup of not doing rehash is not that significant on yeast, even
with a really smaller number of sequences to map. Still, we do have
some scenarios where not doing rehash is better than doing.
** Fourth trial - 1/50
#+begin_src R :results output :session *R* :exports both
33713104 / 50
#+end_src

#+RESULTS:
: [1] 674262.1

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast-fifth",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 28 × 1
   SOURCE                                                                                                                   
   <chr>                                                                                                                    
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-fifth_miniGiraffe16384.…
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-fifth_miniGiraffe2048.c…
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-fifth_miniGiraffe256.csv
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-fifth_miniGiraffe8192.c…
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_yeast-fifth_miniGiraffeNC.csv 
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_1_yeast-fifth_miniGiraffe2048.c…
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_1_yeast-fifth_miniGiraffe8192.c…
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-fifth_miniGiraffe16384.…
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-fifth_miniGiraffe2048.c…
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_yeast-fifth_miniGiraffe256.csv
# ℹ 18 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,736 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0     16384 reading-gbz     0.617      0
 2     512      24 omp                0     16384 reading-seeds   1.08       0
 3     512      24 omp                0     16384 seeds-loop      4.39       0
 4     512      24 omp                0     16384 seeds-loop      4.35       1
 5     512      24 omp                0     16384 seeds-loop      4.33       2
 6     512      24 omp                0     16384 seeds-loop      4.45       3
 7     512      24 omp                0     16384 seeds-loop      4.40       4
 8     512      24 omp                0     16384 seeds-loop      4.36       5
 9     512      24 omp                0     16384 seeds-loop      4.35       6
10     512      24 omp                0     16384 seeds-loop      4.36       7
# ℹ 1,726 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 20 × 5
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0        4.77           4.77
 2      24 omp             256        4.37           4.37
 3      24 omp            2048        3.85           3.85
 4      24 omp            8192        3.88           3.88
 5      24 omp           16384        4.45           4.45
 6      48 omp               0        2.97           2.97
 7      48 omp             256        2.39           2.39
 8      48 omp            2048        2.41           2.41
 9      48 omp            8192        2.42           2.42
10      48 omp           16384        3.20           3.20
11      72 omp               0        2.96           2.96
12      72 omp             256        2.34           2.34
13      72 omp            2048        2.33           2.33
14      72 omp            8192        2.32           2.32
15      72 omp           16384        2.40           2.40
16      96 omp               0        2.83           2.83
17      96 omp             256        2.28           2.28
18      96 omp            2048        2.22           2.22
19      96 omp            8192        2.25           2.25
20      96 omp           16384        2.42           2.42
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureJw4rHs.png]]
#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  mutate(Machine = "Intel") %>%
  mutate(Inputset = "1/50") %>%
  print() -> df.intel.1.50
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 20 × 7
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>   
 1      24 omp               0        4.77           4.77 Intel   1/50    
 2      24 omp             256        4.37           4.37 Intel   1/50    
 3      24 omp            2048        3.85           3.85 Intel   1/50    
 4      24 omp            8192        3.88           3.88 Intel   1/50    
 5      24 omp           16384        4.45           4.45 Intel   1/50    
 6      48 omp               0        2.97           2.97 Intel   1/50    
 7      48 omp             256        2.39           2.39 Intel   1/50    
 8      48 omp            2048        2.41           2.41 Intel   1/50    
 9      48 omp            8192        2.42           2.42 Intel   1/50    
10      48 omp           16384        3.20           3.20 Intel   1/50    
11      72 omp               0        2.96           2.96 Intel   1/50    
12      72 omp             256        2.34           2.34 Intel   1/50    
13      72 omp            2048        2.33           2.33 Intel   1/50    
14      72 omp            8192        2.32           2.32 Intel   1/50    
15      72 omp           16384        2.40           2.40 Intel   1/50    
16      96 omp               0        2.83           2.83 Intel   1/50    
17      96 omp             256        2.28           2.28 Intel   1/50    
18      96 omp            2048        2.22           2.22 Intel   1/50    
19      96 omp            8192        2.25           2.25 Intel   1/50    
20      96 omp           16384        2.42           2.42 Intel   1/50
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 20 × 4
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0   1    
 2      24 omp             256   1.09 
 3      24 omp            2048   1.24 
 4      24 omp            8192   1.23 
 5      24 omp           16384   1.07 
 6      48 omp               0   1    
 7      48 omp             256   1.24 
 8      48 omp            2048   1.23 
 9      48 omp            8192   1.23 
10      48 omp           16384   0.930
11      72 omp               0   1    
12      72 omp             256   1.27 
13      72 omp            2048   1.27 
14      72 omp            8192   1.28 
15      72 omp           16384   1.23 
16      96 omp               0   1    
17      96 omp             256   1.24 
18      96 omp            2048   1.27 
19      96 omp            8192   1.26 
20      96 omp           16384   1.17
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figure3lXgaA.png]]
Getting this size was more effective on no-rehashing.

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 4
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp             256   1    
 2      24 omp            2048   1.13 
 3      24 omp            8192   1.13 
 4      24 omp           16384   0.982
 5      48 omp             256   1    
 6      48 omp            2048   0.989
 7      48 omp            8192   0.989
 8      48 omp           16384   0.747
 9      72 omp             256   1    
10      72 omp            2048   1.00 
11      72 omp            8192   1.01 
12      72 omp           16384   0.975
13      96 omp             256   1    
14      96 omp            2048   1.03 
15      96 omp            8192   1.01 
16      96 omp           16384   0.944
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureeb8ENA.png]]
Speedup of not doing rehash is not that significant on yeast, even
with a really smaller number of sequences to map. Still, we do have
some scenarios where not doing rehash is better than doing.
** First AMD trial - 1/8
#+begin_src R :results output :session *R* :exports both
33713104 / 8
#+end_src

#+RESULTS:
: [1] 4214138

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast-eight",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 1
   SOURCE                                                                                                                 
   <chr>                                                                                                                  
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-eight_miniGiraffe16384.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-eight_miniGiraffe256.csv  
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-eight_miniGiraffeNC.csv   
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-eight_miniGiraffe16384.csv
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-eight_miniGiraffe256.csv  
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-eight_miniGiraffeNC.csv   
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-eight_miniGiraffe16384.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-eight_miniGiraffe256.csv  
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-eight_miniGiraffeNC.csv   
10 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_1_yeast-eight_miniGiraffe16384.csv
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,488 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0     16384 reading-gbz     0.408      0
 2     512      24 omp                0     16384 reading-seeds   5.50       0
 3     512      24 omp                0     16384 seeds-loop     16.3        0
 4     512      24 omp                0     16384 seeds-loop     16.3        1
 5     512      24 omp                0     16384 seeds-loop     16.2        2
 6     512      24 omp                0     16384 seeds-loop     16.3        3
 7     512      24 omp                0     16384 seeds-loop     16.3        4
 8     512      24 omp                0     16384 seeds-loop     16.3        5
 9     512      24 omp                0     16384 seeds-loop     16.3        6
10     512      24 omp                0     16384 seeds-loop     16.3        7
# ℹ 1,478 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop" & CacheSize != 2048) %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 12 × 5
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0       19.5           19.5 
 2      24 omp             256       16.2           16.2 
 3      24 omp           16384       16.4           16.4 
 4      48 omp               0        9.74           9.74
 5      48 omp             256        8.17           8.17
 6      48 omp           16384        8.24           8.24
 7      72 omp               0        7.47           7.47
 8      72 omp             256        6.17           6.17
 9      72 omp           16384        6.24           6.24
10      96 omp               0        7.06           7.06
11      96 omp             256        5.70           5.70
12      96 omp           16384        5.78           5.78
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureABmpGY.png]]

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  mutate(Machine = "AMD") %>%
  mutate(Inputset = "1/8") %>%
  print() -> df.amd.1.8
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12 × 7
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>   
 1      24 omp               0       19.5           19.5  AMD     1/8     
 2      24 omp             256       16.2           16.2  AMD     1/8     
 3      24 omp           16384       16.4           16.4  AMD     1/8     
 4      48 omp               0        9.74           9.74 AMD     1/8     
 5      48 omp             256        8.17           8.17 AMD     1/8     
 6      48 omp           16384        8.24           8.24 AMD     1/8     
 7      72 omp               0        7.47           7.47 AMD     1/8     
 8      72 omp             256        6.17           6.17 AMD     1/8     
 9      72 omp           16384        6.24           6.24 AMD     1/8     
10      96 omp               0        7.06           7.06 AMD     1/8     
11      96 omp             256        5.70           5.70 AMD     1/8     
12      96 omp           16384        5.78           5.78 AMD     1/8
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12 × 4
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.20
 3      24 omp           16384    1.19
 4      48 omp               0    1   
 5      48 omp             256    1.19
 6      48 omp           16384    1.18
 7      72 omp               0    1   
 8      72 omp             256    1.21
 9      72 omp           16384    1.20
10      96 omp               0    1   
11      96 omp             256    1.24
12      96 omp           16384    1.22
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureRtC2zR.png]]
Getting this size was more effective on no-rehashing.

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 8 × 4
# Groups:   Threads, Scheduler [4]
  Threads Scheduler CacheSize Speedup
    <int> <chr>         <int>   <dbl>
1      24 omp             256   1    
2      24 omp           16384   0.989
3      48 omp             256   1    
4      48 omp           16384   0.992
5      72 omp             256   1    
6      72 omp           16384   0.988
7      96 omp             256   1    
8      96 omp           16384   0.985
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureuIDfSf.png]]

** Second AMD trial - 1/10
#+begin_src R :results output :session *R* :exports both
33713104 / 10
#+end_src

#+RESULTS:
: [1] 3371310

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast-ten",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 24 × 1
   SOURCE                                                                                                               
   <chr>                                                                                                                
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-ten_miniGiraffe16384.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-ten_miniGiraffe256.csv  
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-ten_miniGiraffeNC.csv   
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-ten_miniGiraffe16384.csv
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-ten_miniGiraffe256.csv  
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-ten_miniGiraffeNC.csv   
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-ten_miniGiraffe16384.csv
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-ten_miniGiraffe256.csv  
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-ten_miniGiraffeNC.csv   
10 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_1_yeast-ten_miniGiraffe16384.csv
# ℹ 14 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,488 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0     16384 reading-gbz     0.410      0
 2     512      24 omp                0     16384 reading-seeds   4.19       0
 3     512      24 omp                0     16384 seeds-loop     13.1        0
 4     512      24 omp                0     16384 seeds-loop     13.1        1
 5     512      24 omp                0     16384 seeds-loop     13.1        2
 6     512      24 omp                0     16384 seeds-loop     13.1        3
 7     512      24 omp                0     16384 seeds-loop     13.1        4
 8     512      24 omp                0     16384 seeds-loop     13.1        5
 9     512      24 omp                0     16384 seeds-loop     13.1        6
10     512      24 omp                0     16384 seeds-loop     13.1        7
# ℹ 1,478 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 12 × 5
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0       15.5           15.5 
 2      24 omp             256       13.0           13.0 
 3      24 omp           16384       13.1           13.1 
 4      48 omp               0        7.77           7.77
 5      48 omp             256        6.49           6.49
 6      48 omp           16384        6.55           6.55
 7      72 omp               0        6.00           6.00
 8      72 omp             256        4.95           4.95
 9      72 omp           16384        4.96           4.96
10      96 omp               0        5.66           5.66
11      96 omp             256        4.59           4.59
12      96 omp           16384        4.64           4.64
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figuremAzXMQ.png]]

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  mutate(Machine = "AMD") %>%
  mutate(Inputset = "1/10") %>%
  print() -> df.amd.1.10
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12 × 7
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>   
 1      24 omp               0       15.5           15.5  AMD     1/10    
 2      24 omp             256       13.0           13.0  AMD     1/10    
 3      24 omp           16384       13.1           13.1  AMD     1/10    
 4      48 omp               0        7.77           7.77 AMD     1/10    
 5      48 omp             256        6.49           6.49 AMD     1/10    
 6      48 omp           16384        6.55           6.55 AMD     1/10    
 7      72 omp               0        6.00           6.00 AMD     1/10    
 8      72 omp             256        4.95           4.95 AMD     1/10    
 9      72 omp           16384        4.96           4.96 AMD     1/10    
10      96 omp               0        5.66           5.66 AMD     1/10    
11      96 omp             256        4.59           4.59 AMD     1/10    
12      96 omp           16384        4.64           4.64 AMD     1/10
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12 × 4
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.19
 3      24 omp           16384    1.18
 4      48 omp               0    1   
 5      48 omp             256    1.20
 6      48 omp           16384    1.19
 7      72 omp               0    1   
 8      72 omp             256    1.21
 9      72 omp           16384    1.21
10      96 omp               0    1   
11      96 omp             256    1.23
12      96 omp           16384    1.22
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureeIguol.png]]
Getting this size was more effective on no-rehashing.

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp             256   1    
 2      24 omp           16384   1.01 
 3      24 ws              256   1    
 4      24 ws            16384   0.970
 5      48 omp             256   1    
 6      48 omp           16384   0.910
 7      48 ws              256   1    
 8      48 ws            16384   1.12 
 9      72 omp             256   1    
10      72 omp           16384   0.976
11      72 ws              256   1    
12      72 ws            16384   1.00 
13      96 omp             256   1    
14      96 omp           16384   1.11 
15      96 ws              256   1    
16      96 ws            16384   0.987
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figurePMT8CG.png]]
Speedup of not doing rehash is not that significant on yeast, even
with a really smaller number of sequences to map. Still, we do have
some scenarios where not doing rehash is better than doing.
** Third AMD trial - 1/50
#+begin_src R :results output :session *R* :exports both
33713104 / 50
#+end_src

#+RESULTS:
: [1] 674262.1

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="yeast-fifth",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 32 × 1
   SOURCE                                                                                                                 
   <chr>                                                                                                                  
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-fifth_miniGiraffe16384.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-fifth_miniGiraffe256.csv  
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-fifth_miniGiraffe8192.csv 
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_0_yeast-fifth_miniGiraffeNC.csv   
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-fifth_miniGiraffe16384.csv
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-fifth_miniGiraffe256.csv  
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-fifth_miniGiraffe8192.csv 
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_24_omp_1_yeast-fifth_miniGiraffeNC.csv   
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-fifth_miniGiraffe16384.csv
10 /soe/jessicadagostini/miniGiraffe/iiswc25/amdepyc955464-coreprocessor/6-7/512_48_omp_0_yeast-fifth_miniGiraffe256.csv  
# ℹ 22 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,984 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0     16384 reading-gbz     0.407      0
 2     512      24 omp                0     16384 reading-seeds   0.875      0
 3     512      24 omp                0     16384 seeds-loop      2.58       0
 4     512      24 omp                0     16384 seeds-loop      2.58       1
 5     512      24 omp                0     16384 seeds-loop      2.59       2
 6     512      24 omp                0     16384 seeds-loop      2.56       3
 7     512      24 omp                0     16384 seeds-loop      2.57       4
 8     512      24 omp                0     16384 seeds-loop      2.58       5
 9     512      24 omp                0     16384 seeds-loop      2.64       6
10     512      24 omp                0     16384 seeds-loop      2.56       7
# ℹ 1,974 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 16 × 5
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0       3.14           3.14 
 2      24 omp             256       2.62           2.62 
 3      24 omp            8192       2.61           2.61 
 4      24 omp           16384       2.64           2.64 
 5      48 omp               0       1.62           1.62 
 6      48 omp             256       1.35           1.35 
 7      48 omp            8192       1.35           1.35 
 8      48 omp           16384       1.36           1.36 
 9      72 omp               0       1.27           1.27 
10      72 omp             256       1.04           1.04 
11      72 omp            8192       1.04           1.04 
12      72 omp           16384       1.06           1.06 
13      96 omp               0       1.19           1.19 
14      96 omp             256       0.973          0.973
15      96 omp            8192       0.979          0.979
16      96 omp           16384       0.989          0.989
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureVEW5Ei.png]]
#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  mutate(Machine = "AMD") %>%
  mutate(Inputset = "1/50") %>%
  print() -> df.amd.1.50
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 7
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>   
 1      24 omp               0       3.14           3.14  AMD     1/50    
 2      24 omp             256       2.62           2.62  AMD     1/50    
 3      24 omp            8192       2.61           2.61  AMD     1/50    
 4      24 omp           16384       2.64           2.64  AMD     1/50    
 5      48 omp               0       1.62           1.62  AMD     1/50    
 6      48 omp             256       1.35           1.35  AMD     1/50    
 7      48 omp            8192       1.35           1.35  AMD     1/50    
 8      48 omp           16384       1.36           1.36  AMD     1/50    
 9      72 omp               0       1.27           1.27  AMD     1/50    
10      72 omp             256       1.04           1.04  AMD     1/50    
11      72 omp            8192       1.04           1.04  AMD     1/50    
12      72 omp           16384       1.06           1.06  AMD     1/50    
13      96 omp               0       1.19           1.19  AMD     1/50    
14      96 omp             256       0.973          0.973 AMD     1/50    
15      96 omp            8192       0.979          0.979 AMD     1/50    
16      96 omp           16384       0.989          0.989 AMD     1/50
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 × 4
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.20
 3      24 omp            8192    1.21
 4      24 omp           16384    1.19
 5      48 omp               0    1   
 6      48 omp             256    1.20
 7      48 omp            8192    1.20
 8      48 omp           16384    1.19
 9      72 omp               0    1   
10      72 omp             256    1.23
11      72 omp            8192    1.23
12      72 omp           16384    1.20
13      96 omp               0    1   
14      96 omp             256    1.22
15      96 omp            8192    1.22
16      96 omp           16384    1.20
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureSFWvKh.png]]
Getting this size was more effective on no-rehashing.

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12 × 4
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp             256   1    
 2      24 omp            8192   1.01 
 3      24 omp           16384   0.994
 4      48 omp             256   1    
 5      48 omp            8192   1.00 
 6      48 omp           16384   0.989
 7      72 omp             256   1    
 8      72 omp            8192   1.00 
 9      72 omp           16384   0.981
10      96 omp             256   1    
11      96 omp            8192   0.994
12      96 omp           16384   0.983
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureeb8ENA.png]]
Speedup of not doing rehash is not that significant on yeast, even
with a really smaller number of sequences to map. Still, we do have
some scenarios where not doing rehash is better than doing.
** Investigate rehash bottleneck for Grch38
Let's see if on Grch38 we can see changes. We know that it will not be
with the complete avoidance of rehash (see results on 6.4), but let's
try with the best case that we found out there.

Pipeline file - pipeline-6-7.py
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             skip = 1,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Runtime = X2, Thread = X3)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="grch38-ten",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 32 × 1
   SOURCE                                                                                                                   
   <chr>                                                                                                                    
 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_grch38-ten_miniGiraffe2048.csv
 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_grch38-ten_miniGiraffe256.csv 
 3 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_grch38-ten_miniGiraffe32768.c…
 4 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_0_grch38-ten_miniGiraffeNC.csv  
 5 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_omp_1_grch38-ten_miniGiraffe32768.c…
 6 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_grch38-ten_miniGiraffe2048.csv 
 7 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_grch38-ten_miniGiraffe256.csv  
 8 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_24_ws_0_grch38-ten_miniGiraffeNC.csv   
 9 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_grch38-ten_miniGiraffe2048.csv
10 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/512_48_omp_0_grch38-ten_miniGiraffe256.csv 
# ℹ 22 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("Batches", "Threads", "Scheduler", "Repetition", "XX7", "CacheSize"), sep="_") %>%
    mutate(CacheSize = str_replace_all(CacheSize, "([minGrafe.csv])", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    mutate(CacheSize = ifelse(CacheSize == "NC", "0", CacheSize)) %>%
    mutate(Batches = as.integer(Batches),
           Threads = as.integer(Threads),
           Repetition = as.integer(Repetition),
           CacheSize = as.integer(CacheSize)) %>%
  print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1,984 × 8
   Batches Threads Scheduler Repetition CacheSize Query         Runtime Thread
     <int>   <int> <chr>          <int>     <int> <chr>           <dbl>  <dbl>
 1     512      24 omp                0      2048 reading-gbz      21.8      0
 2     512      24 omp                0      2048 reading-seeds    13.8      0
 3     512      24 omp                0      2048 seeds-loop       13.1      0
 4     512      24 omp                0      2048 seeds-loop       12.9      1
 5     512      24 omp                0      2048 seeds-loop       12.8      2
 6     512      24 omp                0      2048 seeds-loop       12.8      3
 7     512      24 omp                0      2048 seeds-loop       12.7      4
 8     512      24 omp                0      2048 seeds-loop       12.8      5
 9     512      24 omp                0      2048 seeds-loop       13.0      6
10     512      24 omp                0      2048 seeds-loop       12.9      7
# ℹ 1,974 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  filter(Query == "seeds-loop") %>%
  group_by(Threads, Scheduler, Repetition, CacheSize) %>%
  summarize(Makespan = max(Runtime)) %>%
  ungroup() %>%
  group_by(Threads, Scheduler, CacheSize) %>%
  summarize(AvgMakespan = mean(Makespan),
            MedianMakespan = median(Makespan)) %>%
  print() -> df.6.7.makespan
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Threads', 'Scheduler', 'Repetition'. You can override using the `.groups` argument.
`summarise()` has grouped output by 'Threads', 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 28 × 5
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan
     <int> <chr>         <int>       <dbl>          <dbl>
 1      24 omp               0       16.3           16.3 
 2      24 omp             256       14.2           14.2 
 3      24 omp            2048       13.1           13.1 
 4      24 omp           32768       16.0           16.0 
 5      24 ws                0       16.8           16.8 
 6      24 ws              256       13.9           13.9 
 7      24 ws             2048       13.8           13.8 
 8      48 omp               0       12.3           12.3 
 9      48 omp             256        9.05           9.05
10      48 omp            2048       10.4           10.4 
# ℹ 18 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.makespan %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=AvgMakespan, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figure8kkD7Q.png]]

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  #filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  print() -> df.6.7.speedup
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 28 × 4
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp               0    1   
 2      24 omp             256    1.15
 3      24 omp            2048    1.24
 4      24 omp           32768    1.02
 5      24 ws                0    1   
 6      24 ws              256    1.21
 7      24 ws             2048    1.22
 8      48 omp               0    1   
 9      48 omp             256    1.36
10      48 omp            2048    1.18
# ℹ 18 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.speedup %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureQkrlBY.png]]
Getting this size was more effective on no-rehashing.

#+begin_src R :results output :session *R* :exports both
df.6.7.makespan %>%
  ungroup() %>%
  filter(CacheSize != 0) %>%
  group_by(Threads, Scheduler) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  select(Threads, Scheduler, CacheSize, Speedup) %>%
  filter(Scheduler == "omp") %>%
  print() -> df.6.7.rehash
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12 × 4
# Groups:   Threads, Scheduler [4]
   Threads Scheduler CacheSize Speedup
     <int> <chr>         <int>   <dbl>
 1      24 omp             256   1    
 2      24 omp            2048   1.09 
 3      24 omp           32768   0.887
 4      48 omp             256   1    
 5      48 omp            2048   0.866
 6      48 omp           32768   0.695
 7      72 omp             256   1    
 8      72 omp            2048   0.909
 9      72 omp           32768   0.986
10      96 omp             256   1    
11      96 omp            2048   1.12 
12      96 omp           32768   1.26
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
df.6.7.rehash %>%
  mutate(CacheSize = as.factor(CacheSize),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  facet_wrap(~Scheduler) +
  theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figuresZRlgx.png]]
Can the results from ws give a hint of how many reads or seeds per
thread the 72 threads case there was doing to get this speedup? Maybe
can correlate with the openmp same test

Will run manually, one of each, to see

#+begin_src R :results output :session *R* :exports both
options(crayon.enabled = FALSE)
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))

read_traces <- function(file) {
    read_csv(file,
             progress=FALSE,
             col_names=FALSE,
             col_types=cols()) %>%
        rename(Query = X1, Start = X2, End = X3, Thread = X4)
}
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
FOLDER="/soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7"
df <- tibble(SOURCE = list.files(FOLDER,
                                 pattern="work_per(.*).csv",
                                 recursive=TRUE,
                                 full.names=TRUE)
             )
df
#+end_src

#+RESULTS:
: # A tibble: 2 × 1
:   SOURCE                                                                                                      
:   <chr>                                                                                                       
: 1 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/work_per_thread_grch38_omp.csv
: 2 /soe/jessicadagostini/miniGiraffe/iiswc25/intelxeonplatinum8260cpu@240ghz/6-7/work_per_thread_grch38_ws.csv

#+begin_src R :results output :session *R* :exports both
df %>%
    mutate(DATA = map(SOURCE, read_traces)) %>%
    separate(SOURCE, c("XX1", "XX2", "XX3", "XX4", "XX5", "XX6", "XX7", "EXP"), sep="/") %>%
    separate(EXP, c("XX8", "XX9", "XX10", "XX11", "Scheduler"), sep="_") %>%
    mutate(Scheduler = str_replace_all(Scheduler, ".csv", "")) %>%
    select(-contains("XX")) %>%
    unnest(DATA) %>%
    print() -> df.6.7
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 12,879,736 × 5
   Scheduler Query             Start       End Thread
   <chr>     <chr>             <dbl>     <dbl>  <dbl>
 1 omp       reading-seeds 10987522. 10987536.      0
 2 omp       reading-gbz   10987536. 10987558.      0
 3 omp       seeds-loop    10987558. 10987558.      0
 4 omp       seeds-loop    10987558. 10987558.      0
 5 omp       seeds-loop    10987558. 10987558.      0
 6 omp       seeds-loop    10987558. 10987558.      0
 7 omp       seeds-loop    10987558. 10987558.      0
 8 omp       seeds-loop    10987558. 10987558.     50
 9 omp       seeds-loop    10987558. 10987558.     50
10 omp       seeds-loop    10987558. 10987558.     50
# ℹ 12,879,726 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.6.7 %>%
  mutate(Duration = End - Start) %>%
  group_by(Scheduler, Thread) %>%
  filter(Query == "seeds-loop") %>%
  summarize(Qntd = n(),
            Runtime = sum(Duration)) %>%
  print() -> df.work
#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Scheduler'. You can override using the `.groups` argument.
# A tibble: 144 × 4
# Groups:   Scheduler [2]
   Scheduler Thread   Qntd Runtime
   <chr>      <dbl>  <int>   <dbl>
 1 omp            0  75264    7.40
 2 omp            1  80384    7.32
 3 omp            2 114176    6.64
 4 omp            3  76288    7.53
 5 omp            4  87040    7.20
 6 omp            5  77824    7.44
 7 omp            6  90624    7.12
 8 omp            7  84480    7.34
 9 omp            8  76800    7.49
10 omp            9 114688    6.70
# ℹ 134 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.work %>%
  summarize(max(Qntd), max(Runtime))
#+end_src

#+RESULTS:
: # A tibble: 2 × 3
:   Scheduler `max(Qntd)` `max(Runtime)`
:   <chr>           <int>          <dbl>
: 1 omp            117248           7.77
: 2 ws             110080          10.5

#+begin_src R :results output :session *R* :exports both
df.work %>%
  filter(Runtime == max(Runtime))
#+end_src

#+RESULTS:
: # A tibble: 2 × 4
: # Groups:   Scheduler [2]
:   Scheduler Thread  Qntd Runtime
:   <chr>      <dbl> <int>   <dbl>
: 1 omp           53 66560    7.77
: 2 ws             8 76288   10.5

#+begin_src R :results output :session *R* :exports both
df.work %>%
  filter(Thread == 2)
#+end_src

#+RESULTS:
: # A tibble: 2 × 4
: # Groups:   Scheduler [2]
:   Scheduler Thread   Qntd Runtime
:   <chr>      <dbl>  <int>   <dbl>
: 1 omp            2 114176    6.64
: 2 ws             2  99328    8.75

Despite presenting a better speedup, the runtime of ws scheduler is
bigger than omp, so it is not bringing benefits to the original
approach. If the ws runtime were faster than omp and we had gains with
the rehash stuff, then we could use it. But it is not the case.
** Summary
#+begin_src R :results output :session *R* :exports both
df.intel.1.8 %>%
  bind_rows(df.intel.1.10, df.intel.1.50, df.amd.1.8, df.amd.1.10, df.amd.1.50) %>%
  print() -> df.yeast
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 108 × 7
# Groups:   Threads, Scheduler [8]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>   
 1      24 omp               0        30.6           30.6 Intel   1/8     
 2      24 omp             256        26.0           26.0 Intel   1/8     
 3      24 omp           16384        24.9           24.9 Intel   1/8     
 4      24 ws                0        33.0           33.0 Intel   1/8     
 5      24 ws              256        28.8           28.8 Intel   1/8     
 6      24 ws            16384        24.8           24.8 Intel   1/8     
 7      48 omp               0        23.4           23.4 Intel   1/8     
 8      48 omp             256        18.5           18.5 Intel   1/8     
 9      48 omp           16384        18.2           18.2 Intel   1/8     
10      48 ws                0        24.1           24.1 Intel   1/8     
# ℹ 98 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results output :session *R* :exports both
df.yeast %>%
  ungroup() %>%
  filter(Scheduler == "omp" & CacheSize >= 0) %>%
  group_by(Machine, Inputset, Threads) %>%
  mutate(Baseline = first(AvgMakespan),
         Speedup = Baseline/AvgMakespan) %>%
  print() -> df.yeast.speed
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 84 × 9
# Groups:   Machine, Inputset, Threads [24]
   Threads Scheduler CacheSize AvgMakespan MedianMakespan Machine Inputset Baseline Speedup
     <int> <chr>         <int>       <dbl>          <dbl> <chr>   <chr>       <dbl>   <dbl>
 1      24 omp               0        30.6           30.6 Intel   1/8          30.6    1   
 2      24 omp             256        26.0           26.0 Intel   1/8          30.6    1.18
 3      24 omp           16384        24.9           24.9 Intel   1/8          30.6    1.23
 4      48 omp               0        23.4           23.4 Intel   1/8          23.4    1   
 5      48 omp             256        18.5           18.5 Intel   1/8          23.4    1.26
 6      48 omp           16384        18.2           18.2 Intel   1/8          23.4    1.28
 7      72 omp               0        19.2           19.2 Intel   1/8          19.2    1   
 8      72 omp             256        14.9           14.9 Intel   1/8          19.2    1.29
 9      72 omp           16384        14.6           14.6 Intel   1/8          19.2    1.32
10      96 omp               0        17.5           17.5 Intel   1/8          17.5    1   
# ℹ 74 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

#+begin_src R :results graphics file :file (org-babel-temp-file "figure" ".png") :exports both :width 1000 :height 400 :session *R*
my_custom_colors <- c("#D95F02", "#7570B3",  
                      "#66A61E", "#E6AB02", "#A6761D", "#666666")
df.yeast.speed %>%
  filter(CacheSize != 2048 & CacheSize > 0) %>%
  mutate(CacheSize = factor(CacheSize, levels = c(0, 256, 2048, 8192, 16384), ordered=TRUE),
         Inputset = factor(Inputset, levels = c("1/8", "1/10", "1/50"), ordered=TRUE),
         Threads = as.factor(Threads)) %>%
  ggplot(aes(x=Threads, y=Speedup, fill=CacheSize)) +
  geom_bar(stat="identity", width=.8, position = "dodge") +
  geom_hline(yintercept = 1, linetype = "dashed") +
  scale_fill_manual(values = my_custom_colors) +
  ylim(0.0, 1.5) +
  facet_grid(Machine~Inputset) +
  theme_bw()+
  theme(legend.position = "top",
        text = element_text(size = 20),
        axis.text.y = element_text(angle = 45, hjust = 1, size=15),
        axis.text.x = element_text(angle = 0, hjust = 0.5, size=15))
#+end_src

#+RESULTS:
[[file:/tmp/babel-IxsbR2/figureGGeTcv.png]]
I have been playing with different quantities of reads for two input
sets: the yeast, and the grch38. These two are bigger than the 1000GP.

For the yeast, I have chopped the input set size by 1/8, 1/10 and 1/50
of the original size. I just got the total size, divided by one of the
factors, and used that portion to run miniGiraffe. Since I am chopping
some reads, I have confirmed what was the new maximum size the
CachedGBWT achieved to run with these new sizes (i.e. the size where
we don't do rehash). Thus, for 1/8 and
1/10, the maximum size is 16384, while for 1/50 was 8192. In the plot
I am showing the speedup of not doing rehash in each scenario. Even
decreasing by a considerable amount the number of reads per thread,
avoiding rehash does not bring much of benefit for most of the
scenarios. For those that it does bring speedup (as on 1/10 with 96
threads and on 1/50 with 24 threads), the gain is not that
expressive. Looking on the 1/50, lowering even more the number of
reads per thread (on 72 and 96 threads) and not performing rehash with
the size of 8192 does not present much of difference of doing the
resize.
One interesting point in here though is that, when running with 16k
size on this smaller version, this bigger capacity affects the runtime
in a negative way. All executions present a slowdown compared to the
original initial capacity of 256. And this goes along with what I find
for the full Grch38 test case, where avoiding rehash completely
requires that the initial capacity of this caching structure to be so
huge that negatively affects the performance.
Testing on AMD, avoiding rehashing does not make any difference on
performance.

* 7 - Exploring different tuning parameters + auto tuning
** Brainstorm of the idea
In this experiment, I need to perform a few tests to explore different
tuning parameters for different input sets.
The idea consists on finding the best perfomer setting for each test
case before running it completely.
There are 3 to 4 dimensions I can play:
- Scheduler (omp or ws)
- Batch size
- GBWT Cache initial capacity (using or not caching structure)
- Number of threads

For the last point, it is hard that the best performer will not be
equal to the biggest quantity of threads available, so I think we can
disregard that.

This testing needs to consist in a few steps:
- Given the input set, generate a smaller version with 10% of the
  total sequences to be mapped
- Generate different combinations of the dimensions to test
- Save the results to later analysis
- Analyze and determine which one got better results
- Run the full execution

Since I will be trying to get the best performer, I think I should try
to run in two scenarios - total cores and total threads. Some machines
does not have more threads than cores, so I just need to make sure
that I will do it correctly.

I will have a script in Python since I think it will be easier to
code. I also have already some pipeline scripts that I can reuse.

Steps to make this happen:
- Change the ~lower_input~ code to always get 10% of the test case
- Create script python with the MiniGiraffePipeline class that will
  receive as parameters the two input files (sequences and gbz)
- First thing on script will be to lower the input
- Input ready, generate test cases (needs to be randomically with all
  possible settings)
- Script must collect how many cores and threads the machine has
- Script must run the application using the lowered input and store
  the tracing results in files for each run
- After everything is collected, the script needs to determine the
  best setting
- (for paper purposes) this part should generate a plot or at least
  store the tracing to further plotting
- With the best setting, we run the full execution
- (for paper purposes) the script should also run the default version
  to compare how better the tuning made the application run
This script is ready and tested on ~iiswc25/tuning-pipeline.py~
** 7.1 - Tuning on kaffirlime
*** 1000GP
Ran on Jun 4
*** Yeast
*** Grch38
Ran on Jun 5
*** Chm13
